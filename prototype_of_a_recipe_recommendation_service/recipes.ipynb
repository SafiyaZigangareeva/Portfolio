{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bb3070",
   "metadata": {},
   "source": [
    "#  Прототип рекомендательного сервиса рецептов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac50ab8",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b8a77",
   "metadata": {},
   "source": [
    "датасет из Epicurious, подготовленный HugoDarwood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03785eb1",
   "metadata": {},
   "source": [
    "## План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45501248",
   "metadata": {},
   "source": [
    " 1.Исследование:\n",
    " - Подготовка данных\n",
    " - Прогноз рейтинга с помощью регрессионных алгоритмов и их ансамблей (), метрика RMSE\n",
    " - Бинаризация целевой переменной в классы `bad` (0, 1) (невкусное), `so-so` (2, 3) (нормальное), `great` (4, 5) (вкусное). \n",
    " - Алгоритмы классификации и подбор метрики для решения задачи прогноза.\n",
    " - Определение метрики на тестовой выборке.\n",
    " - Сохранение лучшей модели.\n",
    " \n",
    " 2.Пищевая ценность и похожие рецепты:\n",
    " - Сбор в датафрейм информации о пищевой ценности продуктов из `FoodData Central API`\n",
    " - Сбор в датафрейм для каждого рецепта из набора данных ссылки на сайт epicurious.com и подробную информацию о нем (название рецепта, рейтинг на платформе и URl). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45608b2",
   "metadata": {},
   "source": [
    "## 0. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1039c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import itertools\n",
    "#Выбор модели\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#Модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Ансамбли\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Метрики\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "#Наивный классификатор\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "#парсинг\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#графики\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a569b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a0c5b",
   "metadata": {},
   "source": [
    "## 1. Прогноз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ba065",
   "metadata": {},
   "source": [
    "### 1.1 Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0332de",
   "metadata": {},
   "source": [
    "Будем использовать датасет из Epicurious, подготовленный HugoDarwood\n",
    "\n",
    "Отфильтруем поля: удалим как можно больше столбцов, которые не относятся к названиями ингридиентов. Если модель обучится на других данных, которые не будут передаваться на вход, то точность прогнозов будет заведомо ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a14055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  rating  calories  protein  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
       "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
       "\n",
       "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
       "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
       "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
       "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
       "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
       "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
       "\n",
       "   ...  yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  \\\n",
       "0  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "1  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "2  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "3  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "4  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "\n",
       "   snack  snack week  turkey  \n",
       "0    0.0         0.0     1.0  \n",
       "1    0.0         0.0     0.0  \n",
       "2    0.0         0.0     0.0  \n",
       "3    0.0         0.0     0.0  \n",
       "4    0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузим датасет и ознакомимся с ним\n",
    "df = pd.read_csv('./data/epi_r.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a471a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20052 entries, 0 to 20051\n",
      "Columns: 680 entries, title to turkey\n",
      "dtypes: float64(679), object(1)\n",
      "memory usage: 104.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "becf718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20052</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>1.593500e+04</td>\n",
       "      <td>15890.000000</td>\n",
       "      <td>1.586900e+04</td>\n",
       "      <td>1.593300e+04</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "      <td>20052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Pastry Dough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.714467</td>\n",
       "      <td>6.322958e+03</td>\n",
       "      <td>100.160793</td>\n",
       "      <td>3.468775e+02</td>\n",
       "      <td>6.225975e+03</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.022741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.340829</td>\n",
       "      <td>3.590460e+05</td>\n",
       "      <td>3840.318527</td>\n",
       "      <td>2.045611e+04</td>\n",
       "      <td>3.333182e+05</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.160123</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.121001</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.037343</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.149080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>3.310000e+02</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>7.110000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.011122e+07</td>\n",
       "      <td>236489.000000</td>\n",
       "      <td>1.722763e+06</td>\n",
       "      <td>2.767511e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                title        rating      calories        protein  \\\n",
       "count           20052  20052.000000  1.593500e+04   15890.000000   \n",
       "unique          17736           NaN           NaN            NaN   \n",
       "top     Pastry Dough            NaN           NaN            NaN   \n",
       "freq               28           NaN           NaN            NaN   \n",
       "mean              NaN      3.714467  6.322958e+03     100.160793   \n",
       "std               NaN      1.340829  3.590460e+05    3840.318527   \n",
       "min               NaN      0.000000  0.000000e+00       0.000000   \n",
       "25%               NaN      3.750000  1.980000e+02       3.000000   \n",
       "50%               NaN      4.375000  3.310000e+02       8.000000   \n",
       "75%               NaN      4.375000  5.860000e+02      27.000000   \n",
       "max               NaN      5.000000  3.011122e+07  236489.000000   \n",
       "\n",
       "                 fat        sodium     #cakeweek    #wasteless  \\\n",
       "count   1.586900e+04  1.593300e+04  20052.000000  20052.000000   \n",
       "unique           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN   \n",
       "mean    3.468775e+02  6.225975e+03      0.000299      0.000050   \n",
       "std     2.045611e+04  3.333182e+05      0.017296      0.007062   \n",
       "min     0.000000e+00  0.000000e+00      0.000000      0.000000   \n",
       "25%     7.000000e+00  8.000000e+01      0.000000      0.000000   \n",
       "50%     1.700000e+01  2.940000e+02      0.000000      0.000000   \n",
       "75%     3.300000e+01  7.110000e+02      0.000000      0.000000   \n",
       "max     1.722763e+06  2.767511e+07      1.000000      1.000000   \n",
       "\n",
       "        22-minute meals  3-ingredient recipes  ...  yellow squash  \\\n",
       "count      20052.000000          20052.000000  ...   20052.000000   \n",
       "unique              NaN                   NaN  ...            NaN   \n",
       "top                 NaN                   NaN  ...            NaN   \n",
       "freq                NaN                   NaN  ...            NaN   \n",
       "mean           0.000848              0.001346  ...       0.001247   \n",
       "std            0.029105              0.036671  ...       0.035288   \n",
       "min            0.000000              0.000000  ...       0.000000   \n",
       "25%            0.000000              0.000000  ...       0.000000   \n",
       "50%            0.000000              0.000000  ...       0.000000   \n",
       "75%            0.000000              0.000000  ...       0.000000   \n",
       "max            1.000000              1.000000  ...       1.000000   \n",
       "\n",
       "              yogurt       yonkers          yuca      zucchini     cookbooks  \\\n",
       "count   20052.000000  20052.000000  20052.000000  20052.000000  20052.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.026332      0.000050      0.000299      0.014861      0.000150   \n",
       "std         0.160123      0.007062      0.017296      0.121001      0.012231   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max         1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           leftovers         snack    snack week        turkey  \n",
       "count   20052.000000  20052.000000  20052.000000  20052.000000  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "mean        0.000349      0.001396      0.000948      0.022741  \n",
       "std         0.018681      0.037343      0.030768      0.149080  \n",
       "min         0.000000      0.000000      0.000000      0.000000  \n",
       "25%         0.000000      0.000000      0.000000      0.000000  \n",
       "50%         0.000000      0.000000      0.000000      0.000000  \n",
       "75%         0.000000      0.000000      0.000000      0.000000  \n",
       "max         1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[11 rows x 680 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f06b4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['yellow squash'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7322a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           Lentil, Apple, and Turkey Wrap \n",
       "rating                                      2.5\n",
       "calories                                  426.0\n",
       "protein                                    30.0\n",
       "fat                                         7.0\n",
       "sodium                                    559.0\n",
       "apple                                       1.0\n",
       "bean                                        1.0\n",
       "cookie                                      1.0\n",
       "fruit                                       1.0\n",
       "kid-friendly                                1.0\n",
       "lentil                                      1.0\n",
       "lettuce                                     1.0\n",
       "sandwich                                    1.0\n",
       "tomato                                      1.0\n",
       "vegetable                                   1.0\n",
       "turkey                                      1.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroka = df.loc[0]\n",
    "stroka[stroka!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a567d",
   "metadata": {},
   "source": [
    "Видно, что столбцы с 0-6 не относятся к ингридиентам и мы можем их удалить. Для каждого рецепта необходимые ингридиенты отмечены \"1\" в соответствующем ингридиенту столбце. Также есть столбцы kid-friendly, bastille day, bon appétit, food processor, new year's eve, winter - которые так же не относятся к ингридиентам, а характеризуют само блюдо.  \n",
    "\n",
    "Надо как-то отделить столбцы, которые не относятся к ингридиентам. Уберем из наименований столбцов те, названия которых встречаются в title - это скорее всего ингридиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f97efcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'saffroned',\n",
       " 'pappadam',\n",
       " 'whale',\n",
       " 'side',\n",
       " 'earth',\n",
       " 'mini',\n",
       " 'zing',\n",
       " 'three',\n",
       " \"peng's\",\n",
       " 'ramos',\n",
       " 'leek',\n",
       " 'suckling',\n",
       " 'adult',\n",
       " 'croquetas',\n",
       " 'waikaloa',\n",
       " 'elixir',\n",
       " 'shortcakes',\n",
       " 'comte',\n",
       " 'cow',\n",
       " 'al',\n",
       " 'blossoms',\n",
       " 'multi',\n",
       " 'mignonette',\n",
       " 'nika',\n",
       " 'hamburgers',\n",
       " 'fillet',\n",
       " 'sachertorte',\n",
       " 'sex',\n",
       " 'lobster',\n",
       " 'year',\n",
       " 'shabu',\n",
       " 'wrap',\n",
       " 'banh',\n",
       " '10',\n",
       " \"bubbe's\",\n",
       " 'flatbread',\n",
       " 'cannoli',\n",
       " 'press',\n",
       " 'pavé',\n",
       " 'spicy',\n",
       " 'papillote',\n",
       " 'res',\n",
       " 'hamburger',\n",
       " 'croissant',\n",
       " 'loudspeaker',\n",
       " 'espresso',\n",
       " 'hudson',\n",
       " 'chilled',\n",
       " 'buffalo',\n",
       " 'ouzo',\n",
       " 'feeling',\n",
       " 'mizuna',\n",
       " 'lassi',\n",
       " 'peanutty',\n",
       " 'lamb',\n",
       " 'reviver',\n",
       " 'cheeses',\n",
       " 'royale',\n",
       " 'slow',\n",
       " 'hawaiian',\n",
       " 'blazer',\n",
       " 'energy',\n",
       " 'chile–rubbed',\n",
       " 'mosel',\n",
       " 'blis',\n",
       " 'nachos',\n",
       " 'bazooka',\n",
       " 'render',\n",
       " \"d'orange\",\n",
       " 'strong',\n",
       " 'thick',\n",
       " 'coats',\n",
       " 'gemelli',\n",
       " 'palmiers',\n",
       " 'late',\n",
       " 'celery',\n",
       " 'gpc',\n",
       " 'prairie',\n",
       " 'gulasch',\n",
       " \"carla's\",\n",
       " 'dogs',\n",
       " 'pisco',\n",
       " \"buffet's\",\n",
       " 'provencales',\n",
       " 'chupacabra',\n",
       " 'francis',\n",
       " 'slab',\n",
       " 'ba',\n",
       " 'garnie',\n",
       " 'out',\n",
       " \"year's\",\n",
       " 'negro',\n",
       " 'sub',\n",
       " 'left',\n",
       " 'quemada',\n",
       " 'kasha',\n",
       " 'variations',\n",
       " 'strawberry–pistachio',\n",
       " 'le',\n",
       " 'twists',\n",
       " \"grandmother's\",\n",
       " 'cane',\n",
       " 'pozole',\n",
       " 'eat',\n",
       " '66',\n",
       " 'cakes',\n",
       " 'scallop',\n",
       " 'share',\n",
       " 'tlalpeno',\n",
       " 'crustes',\n",
       " 'orecchiette',\n",
       " 'salzburger',\n",
       " 'gimlet',\n",
       " 'whispers',\n",
       " 'salisbury',\n",
       " 'mushrooms',\n",
       " 'blt',\n",
       " 'crepes',\n",
       " 'herring',\n",
       " 'hair',\n",
       " 'swedish',\n",
       " 'english',\n",
       " 'basil',\n",
       " \"ethel's\",\n",
       " 'margarita',\n",
       " 'galantine',\n",
       " 'clotted',\n",
       " 'calzones',\n",
       " 'portuguese',\n",
       " 'small',\n",
       " 'vermont',\n",
       " 'link',\n",
       " 'thistle',\n",
       " 'browned',\n",
       " 'staff',\n",
       " 'milanesa',\n",
       " 'mapo',\n",
       " 'berrymisu',\n",
       " 'stuffed',\n",
       " 'rags',\n",
       " 'caponata',\n",
       " 'pavlova',\n",
       " 'man',\n",
       " 'field',\n",
       " 'gloria',\n",
       " 'chop',\n",
       " 'gwa',\n",
       " 'coke',\n",
       " 'nuoc',\n",
       " 'smith',\n",
       " 'pastina',\n",
       " 'blower',\n",
       " \"azul's\",\n",
       " 'khao',\n",
       " 'oreganata',\n",
       " 'sum',\n",
       " 'juniper',\n",
       " 'padian',\n",
       " 'darkest',\n",
       " 'barbecue',\n",
       " 'chowders',\n",
       " 'bulb',\n",
       " 'dutchess',\n",
       " 'retro',\n",
       " 'quinoa',\n",
       " 'grenobloise',\n",
       " 'savoy',\n",
       " 'pisto',\n",
       " 'marblehead',\n",
       " 'dashi',\n",
       " 'people',\n",
       " 'rainstorm',\n",
       " 'artisinal',\n",
       " 'wiley',\n",
       " 'maghrebi',\n",
       " 'bluefish',\n",
       " 'jambon',\n",
       " '7',\n",
       " 'sidecar',\n",
       " 'barely',\n",
       " 'gingercream',\n",
       " \"absinthe's\",\n",
       " 'olla',\n",
       " 'deconstructed',\n",
       " 'noir',\n",
       " 'skewered',\n",
       " 'juices',\n",
       " 'pappagallo',\n",
       " 'heranytokany',\n",
       " 'wood',\n",
       " 'moonraker',\n",
       " 'downer',\n",
       " 'thompson',\n",
       " 'upscale',\n",
       " 'tiganito',\n",
       " 'cremini',\n",
       " 'pearls',\n",
       " '3',\n",
       " 'wake',\n",
       " 'ragoût',\n",
       " 'minced',\n",
       " 'silken',\n",
       " 'breasts',\n",
       " 'rutabagas',\n",
       " 'aqua',\n",
       " 'blackberry',\n",
       " 'baltimore',\n",
       " 'fajita',\n",
       " 'anchovy',\n",
       " 'marbleized',\n",
       " 'wedge',\n",
       " 'buttermilk',\n",
       " 'perfectly',\n",
       " 'irish',\n",
       " 'roulades',\n",
       " 'eastern',\n",
       " 'bagels',\n",
       " 'coq',\n",
       " 'karo',\n",
       " 'delights',\n",
       " 'flank',\n",
       " 'luck',\n",
       " 'mesclun',\n",
       " 'pandowdy',\n",
       " 'miguel',\n",
       " 'chocolat',\n",
       " \"goat's\",\n",
       " 'whipped',\n",
       " 'trim',\n",
       " 'yummy',\n",
       " 'tater',\n",
       " 'flamed',\n",
       " 'boulevardier',\n",
       " 'cumin',\n",
       " 'modern',\n",
       " 'affogato',\n",
       " 'panang',\n",
       " 'updated',\n",
       " 'yau',\n",
       " 'amigos',\n",
       " \"jeanne's\",\n",
       " 'parisian',\n",
       " 'sorghum',\n",
       " 'dunk',\n",
       " 'age',\n",
       " 'verte',\n",
       " 'prawns',\n",
       " 'crabs',\n",
       " 'hollywood',\n",
       " 'stollenkonfekt',\n",
       " 'jumbleberry',\n",
       " 'floating',\n",
       " 'rickey',\n",
       " 'kimchi',\n",
       " \"n'awlins\",\n",
       " 'surf',\n",
       " 'barry',\n",
       " 'margaritas',\n",
       " 'noël',\n",
       " \"lion's\",\n",
       " 'fruitcake',\n",
       " 'velvety',\n",
       " 'clams',\n",
       " 'ever',\n",
       " 'russet',\n",
       " 'london',\n",
       " 'hanger',\n",
       " 'salsicce:',\n",
       " 'portobello',\n",
       " 'mold',\n",
       " 'pineapple',\n",
       " 'fruited',\n",
       " 'tobiko',\n",
       " 'avgolemono',\n",
       " 'chutneys',\n",
       " 'sustainable',\n",
       " 'sancocho',\n",
       " 'capucine',\n",
       " 'american',\n",
       " 'instant',\n",
       " 'tangerines',\n",
       " 'endive',\n",
       " 'brochettes',\n",
       " 'refrigerator',\n",
       " 'taglierini',\n",
       " 'à',\n",
       " 'sticky',\n",
       " 'aux',\n",
       " 'piquillo',\n",
       " 'loaves',\n",
       " 'nests',\n",
       " 'cuminseed',\n",
       " 'chip',\n",
       " 'huevos',\n",
       " \"l'orange\",\n",
       " 'woo',\n",
       " 'peasant',\n",
       " 'dutch',\n",
       " \"bachelor's\",\n",
       " 'fairy',\n",
       " 'blueberry',\n",
       " 'blarney',\n",
       " 'kok',\n",
       " 'romana',\n",
       " 'buns',\n",
       " 'makeua',\n",
       " 'grand',\n",
       " 'malt',\n",
       " 'meatballs:',\n",
       " 'raisins',\n",
       " 'sugar',\n",
       " 'moutarde',\n",
       " 'bakes',\n",
       " 'crunchies',\n",
       " 'butter–sriracha',\n",
       " 'sprouts',\n",
       " 'stripes',\n",
       " 'adonis',\n",
       " 'radicchio',\n",
       " 'marbled',\n",
       " 'korean',\n",
       " 'singapore',\n",
       " 'boursin',\n",
       " 'tomato–cashew',\n",
       " \"farmers'\",\n",
       " \"tiger's\",\n",
       " 'cut',\n",
       " 'sables',\n",
       " '#67',\n",
       " 'parmesan–black',\n",
       " 'thin',\n",
       " 'olivier',\n",
       " 'plat',\n",
       " 'pissaladieres',\n",
       " 'borracho',\n",
       " 'wednesday',\n",
       " 'braciola',\n",
       " 'comté',\n",
       " 'brenda',\n",
       " 'liqueurs',\n",
       " \"voula's\",\n",
       " 'skinned',\n",
       " \"alba's\",\n",
       " 'carpaccio',\n",
       " 'mintz',\n",
       " 'flower',\n",
       " 'agatha',\n",
       " 'rockefeller',\n",
       " 'stellar',\n",
       " 'welsh',\n",
       " 'whole',\n",
       " 'speedy',\n",
       " 'trapanese',\n",
       " 'broiled',\n",
       " 'saté',\n",
       " 'monte',\n",
       " 'spiked',\n",
       " 'battered',\n",
       " 'vareniki',\n",
       " 'la',\n",
       " \"gialina's\",\n",
       " 'olives',\n",
       " 'puerta',\n",
       " 'gelees',\n",
       " 'country',\n",
       " 'bleu',\n",
       " 'pinwheels',\n",
       " 'colin',\n",
       " 'collard',\n",
       " \"l'amour\",\n",
       " 'ground',\n",
       " 'pierogies',\n",
       " \"acres'\",\n",
       " 'rican',\n",
       " 'quinces',\n",
       " \"irene's\",\n",
       " 'pickles',\n",
       " 'tabasco',\n",
       " 'grouper',\n",
       " 'crumbles',\n",
       " 'hungarian',\n",
       " 'baklava',\n",
       " 'bistro',\n",
       " 'jars',\n",
       " 'delicious',\n",
       " 'fregola',\n",
       " 'handmade',\n",
       " 'diamonds',\n",
       " 'hazelnut',\n",
       " 'fingerling',\n",
       " 'oaxaca',\n",
       " 'brownie',\n",
       " 'crostata',\n",
       " 'frico',\n",
       " 'oysters',\n",
       " 'lebkuchengewurz',\n",
       " 'paula',\n",
       " 'mista',\n",
       " 'mincemeat',\n",
       " 'fattoush',\n",
       " 'brownies',\n",
       " 'pepperoni',\n",
       " 'persimmons',\n",
       " 'liberty',\n",
       " 'quail',\n",
       " 'slack',\n",
       " 'unstuffed',\n",
       " 'farmers',\n",
       " 'persian',\n",
       " 'licorice',\n",
       " 'confit',\n",
       " 'coins',\n",
       " 'bitter',\n",
       " 'loads',\n",
       " 'tzimmes',\n",
       " 'nasturtiums',\n",
       " 'en',\n",
       " 'stinger',\n",
       " 'rutabaga',\n",
       " 'rösti',\n",
       " 'béchamel',\n",
       " 'taleggio',\n",
       " 'ripiene',\n",
       " 'scramble',\n",
       " 'lazy',\n",
       " 'benne',\n",
       " 'jeweled',\n",
       " 'coppa',\n",
       " 'stout',\n",
       " 'jalebi',\n",
       " 'giada',\n",
       " 'sandmartin',\n",
       " 'paccheri',\n",
       " 'mousse',\n",
       " 'crabapple',\n",
       " 'honeydew',\n",
       " 'pailles',\n",
       " 'culross',\n",
       " 'brunswick',\n",
       " 'tan',\n",
       " 'thumbprint',\n",
       " 'chimay',\n",
       " \"gladines'\",\n",
       " 'winner',\n",
       " 'gem',\n",
       " 'without',\n",
       " 'smash',\n",
       " 'appetizer',\n",
       " 'organic',\n",
       " 'tippler',\n",
       " 'petrale',\n",
       " 'chilies',\n",
       " 'apples',\n",
       " 'corona',\n",
       " 'pendennis',\n",
       " 'fideos',\n",
       " 'baskets',\n",
       " 'tennessee',\n",
       " 'eggnoggin',\n",
       " 'pastiera',\n",
       " 'tier',\n",
       " 'buby',\n",
       " 'ripened',\n",
       " 'bran',\n",
       " 'palate',\n",
       " 'moqueca',\n",
       " 'poireaux',\n",
       " \"lee's\",\n",
       " 'enchiladas',\n",
       " 'bulgarian',\n",
       " 'balsamic–red',\n",
       " 'chorizo',\n",
       " 'kiwis',\n",
       " 'gallette',\n",
       " 'rou',\n",
       " 'county',\n",
       " 'storm',\n",
       " 'waldorf',\n",
       " 'yassa',\n",
       " 'cheese',\n",
       " 'cranberry',\n",
       " 'farm',\n",
       " 'balls',\n",
       " \"angel's\",\n",
       " 'noix',\n",
       " 'eyeballs',\n",
       " 'romanesco',\n",
       " 'clean',\n",
       " 'cove',\n",
       " 'yam',\n",
       " 'thanksgiving',\n",
       " 'hoffman',\n",
       " 'opulent',\n",
       " 'mezcal',\n",
       " 'shaped',\n",
       " 'squabs',\n",
       " 'printanier',\n",
       " 'yeasted',\n",
       " 'amandine',\n",
       " 'maraschino',\n",
       " 'barbequed',\n",
       " 'miller',\n",
       " 'yams',\n",
       " 'anchoiade',\n",
       " \"laxmi's\",\n",
       " 'corinth',\n",
       " 'spiedino',\n",
       " \"nobu's\",\n",
       " 'flanagan',\n",
       " 'sampler',\n",
       " 'encrusted',\n",
       " 'roe',\n",
       " \"ben's\",\n",
       " 'misto',\n",
       " 'market',\n",
       " 'chess',\n",
       " 'soupe',\n",
       " 'squid',\n",
       " 'jollof',\n",
       " 'schnapps',\n",
       " 'alexander',\n",
       " 'spiced',\n",
       " 'quiches',\n",
       " 'sauerbraten',\n",
       " \"mae's\",\n",
       " 'grapefruit–poppy',\n",
       " 'shaw',\n",
       " 'artisanal',\n",
       " 'brown',\n",
       " 'cavolo',\n",
       " 'oval',\n",
       " 'skillet',\n",
       " 'ssäm',\n",
       " 'alt',\n",
       " 'inside',\n",
       " 'broth',\n",
       " 'nage',\n",
       " 'deborah',\n",
       " 'beach',\n",
       " 'pilaf',\n",
       " 'tijuana',\n",
       " 'bait',\n",
       " 'rub',\n",
       " 'lady',\n",
       " 'gelée',\n",
       " 'kentucky',\n",
       " 'popcorn',\n",
       " 'perciatelli',\n",
       " 'hollandaise',\n",
       " 'tetrazzini',\n",
       " 'size',\n",
       " 'turnips',\n",
       " 'wings',\n",
       " 'panzanella',\n",
       " 'sticks',\n",
       " 'corned',\n",
       " 'a',\n",
       " 'hotdish',\n",
       " 'shoots',\n",
       " 'crudo',\n",
       " 'heaven',\n",
       " 'mahimahi',\n",
       " 'persillade',\n",
       " 'chermoula',\n",
       " 'glazed',\n",
       " 'yuca',\n",
       " 'eye',\n",
       " 'saint',\n",
       " 'frisée',\n",
       " 'cantaloupe',\n",
       " 'last',\n",
       " 'peanut',\n",
       " 'harvest',\n",
       " 'turron',\n",
       " 'ciabatta',\n",
       " 'chilean',\n",
       " 'batatas',\n",
       " 'küchen',\n",
       " 'orzo',\n",
       " 'pernod',\n",
       " 'toum',\n",
       " 'flans',\n",
       " 'russian',\n",
       " 'warm',\n",
       " 'cebollitas',\n",
       " 'crumbs',\n",
       " 'dr.',\n",
       " 'snowcap',\n",
       " 'tokay',\n",
       " 'patty',\n",
       " 'chocolate',\n",
       " 'budino',\n",
       " 'porcupines',\n",
       " 'branzini',\n",
       " \"glock's\",\n",
       " 'marshmallows',\n",
       " 'reheating',\n",
       " 'key',\n",
       " 'fricassée',\n",
       " 'drizzle',\n",
       " 'costilla',\n",
       " 'pom',\n",
       " 'split',\n",
       " 'mama',\n",
       " 'busting',\n",
       " \"hershey's\",\n",
       " 'ganache',\n",
       " 'grains',\n",
       " 'hotel',\n",
       " 'lion',\n",
       " 'gochujang',\n",
       " 'orleans',\n",
       " 'arctic',\n",
       " 'pansoti',\n",
       " 'shiitakes',\n",
       " 'leaves',\n",
       " 'boccie',\n",
       " 'gimlets',\n",
       " 'lentilles',\n",
       " 'velvet',\n",
       " 'chiffonade',\n",
       " 'stanley',\n",
       " 'milkie',\n",
       " 'savouries',\n",
       " 'colombian',\n",
       " 'aji',\n",
       " 'summer',\n",
       " 'blood',\n",
       " 'helena',\n",
       " 'bouillabaisse',\n",
       " 'pick',\n",
       " 'bag',\n",
       " 'mesquite',\n",
       " 'diavola',\n",
       " 'tie',\n",
       " 'chopped',\n",
       " 'veggies',\n",
       " 'baron',\n",
       " 'corn',\n",
       " 'agrumes',\n",
       " 'dal',\n",
       " 'batidos',\n",
       " 'wilson',\n",
       " 'da',\n",
       " '/',\n",
       " 'roasted',\n",
       " 'vedova',\n",
       " 'millet',\n",
       " \"wendy's\",\n",
       " 'prime',\n",
       " 'peppermint',\n",
       " 'chambord',\n",
       " 'heritage',\n",
       " 'chowchow',\n",
       " 'blackberries',\n",
       " 'baobab',\n",
       " 'deviled',\n",
       " 'sloe',\n",
       " 'dulce',\n",
       " 'pigeon',\n",
       " 'smoothie',\n",
       " 'swirl',\n",
       " 'szechwan',\n",
       " \"dan's\",\n",
       " 'up',\n",
       " 'brussels',\n",
       " 'garam',\n",
       " 'verciano',\n",
       " 'ode',\n",
       " 'nutty',\n",
       " 'crusta',\n",
       " \"mills's\",\n",
       " 'harissa',\n",
       " 'prickly',\n",
       " 'aloe',\n",
       " 'elizabeth',\n",
       " 'curry–marinated',\n",
       " 'sage',\n",
       " 'bananas',\n",
       " 'toulouse',\n",
       " 'wine–marinated',\n",
       " 'cheddar',\n",
       " 'amarillo',\n",
       " 'chahan',\n",
       " 'sante',\n",
       " 'lattes',\n",
       " 'festival',\n",
       " 'fines',\n",
       " 'pulled',\n",
       " 'camarones',\n",
       " \"roznowska's\",\n",
       " 'salamon',\n",
       " 'banana',\n",
       " 'divorciados',\n",
       " 'macaroon',\n",
       " \"hoppin'\",\n",
       " 'gingery',\n",
       " 'wine',\n",
       " 'purses',\n",
       " 'conde',\n",
       " 'northwest',\n",
       " 'pesce',\n",
       " 'belle',\n",
       " 'carroty',\n",
       " 'trinidadian',\n",
       " 'colcannon',\n",
       " 'fritters',\n",
       " 'saumon',\n",
       " 'sephardic',\n",
       " 'lisu',\n",
       " 'jellies',\n",
       " 'enchilada',\n",
       " 'brie',\n",
       " 'millennium',\n",
       " 'aguacate',\n",
       " 'mockingbird',\n",
       " 'ultra',\n",
       " 'polo',\n",
       " 'moo',\n",
       " 'gingersnap',\n",
       " 'sumac',\n",
       " 'serrano',\n",
       " 'maltaise',\n",
       " 'ravigote',\n",
       " 'sunshine',\n",
       " 'sazerac',\n",
       " 'andré',\n",
       " 'hole',\n",
       " 'pork',\n",
       " 'norma',\n",
       " 'pope',\n",
       " 'archbishop',\n",
       " 'tía',\n",
       " 'bouillon',\n",
       " 'slings',\n",
       " 'coriander',\n",
       " 'marble',\n",
       " 'lychees',\n",
       " 'shakes',\n",
       " 'cup',\n",
       " 'forest',\n",
       " 'treacle',\n",
       " 'cremes',\n",
       " 'for',\n",
       " 'pronto',\n",
       " 'doughnut',\n",
       " 'souffléed',\n",
       " 'nectarines',\n",
       " 'chops',\n",
       " 'verjus',\n",
       " 'faced',\n",
       " 'boil',\n",
       " 'potage',\n",
       " 'st',\n",
       " 'beans',\n",
       " 'kashmiri',\n",
       " 'florida',\n",
       " 'fruits',\n",
       " 'islands',\n",
       " 'santiago',\n",
       " 'sesame',\n",
       " 'microgreens',\n",
       " 'chewy',\n",
       " 'blondie',\n",
       " 'pastrami',\n",
       " 'biscuit',\n",
       " 'sauternes',\n",
       " 'rabbit',\n",
       " 'seven',\n",
       " \"pop's\",\n",
       " 'carrozza',\n",
       " 'gruyère',\n",
       " \"sybil's\",\n",
       " 'mince',\n",
       " 'frosting',\n",
       " \"grill's\",\n",
       " 'red',\n",
       " 'fondant',\n",
       " 'liver',\n",
       " 'aioli',\n",
       " 'strip',\n",
       " 'smokey',\n",
       " 'mignonnette',\n",
       " 'kotleti',\n",
       " 'per',\n",
       " 'roasti',\n",
       " 'kefta',\n",
       " 'bo',\n",
       " 'crispiest',\n",
       " 'plantain',\n",
       " 'bishop',\n",
       " 'sharp',\n",
       " 'artillery',\n",
       " 'things',\n",
       " 'steakburger',\n",
       " 'harina',\n",
       " 'scented',\n",
       " 'pirozhki',\n",
       " 'whaler',\n",
       " 'cucumbers',\n",
       " 'kefir',\n",
       " 'pintade',\n",
       " 'seaweed',\n",
       " 'blueberries',\n",
       " 'chili',\n",
       " 'wraps',\n",
       " 'zhoug',\n",
       " 'form',\n",
       " 'steak',\n",
       " 'lechon',\n",
       " \"grandma's\",\n",
       " 'clemenceau',\n",
       " 'ensalada',\n",
       " 'tortes',\n",
       " 'robson',\n",
       " 'ceviche',\n",
       " 'sunrise',\n",
       " 'emulsion',\n",
       " 'denver',\n",
       " 'tassies',\n",
       " 'hue',\n",
       " 'calvado',\n",
       " 'simplest',\n",
       " '“noodle”',\n",
       " 'blush',\n",
       " 'paillards',\n",
       " 'four',\n",
       " 'moussaka',\n",
       " \"bee's\",\n",
       " 'griddlecakes',\n",
       " \"calf's\",\n",
       " 'mi',\n",
       " 'seethed',\n",
       " 'mix',\n",
       " 'hominy',\n",
       " 'happy',\n",
       " 'cola',\n",
       " 'greek',\n",
       " 'charcuterie',\n",
       " 'hero',\n",
       " 'crostini',\n",
       " 'tilapia',\n",
       " \"alice's\",\n",
       " 'arnie’s',\n",
       " 'clambake',\n",
       " 'vermouth',\n",
       " 'lardon',\n",
       " 'fully',\n",
       " 'tuscan',\n",
       " 'plum',\n",
       " 'chai',\n",
       " 'bath',\n",
       " 'lump',\n",
       " 'pain',\n",
       " 'flourless',\n",
       " 'drizzled',\n",
       " 'dominican',\n",
       " 'wisconsin',\n",
       " 'breeze',\n",
       " 'punchy',\n",
       " 'feuille',\n",
       " 'scandinavian',\n",
       " 'kamikaze',\n",
       " 'crumble',\n",
       " 'sparkling',\n",
       " 'coeurs',\n",
       " 'chive',\n",
       " 'mâitre',\n",
       " 'soy',\n",
       " 'dive',\n",
       " 'fastest',\n",
       " 'figgy',\n",
       " 'baptist',\n",
       " 'nib',\n",
       " 'laya',\n",
       " 'fromage',\n",
       " 'croûte',\n",
       " 'chervil',\n",
       " 'sterilize',\n",
       " 'purslane',\n",
       " 'style',\n",
       " 'lardons',\n",
       " 'herby',\n",
       " 'calypso',\n",
       " 'madeira',\n",
       " 'bee',\n",
       " 'nightmare',\n",
       " 'blue',\n",
       " 'strawberries',\n",
       " 'turmeric',\n",
       " 'bonbons',\n",
       " 'morel',\n",
       " 'oxtail',\n",
       " 'pipérade',\n",
       " 'crackers',\n",
       " 'chutney',\n",
       " 'lacquered',\n",
       " 'lau',\n",
       " 'boosting',\n",
       " 'tapioca',\n",
       " 'ponzu',\n",
       " 'amaretto',\n",
       " 'panna',\n",
       " 'step',\n",
       " 'tray',\n",
       " 'patch',\n",
       " 'dish',\n",
       " 'caramelized',\n",
       " 'by',\n",
       " 'achiote',\n",
       " 'beluga',\n",
       " 'cacio',\n",
       " 'carolina',\n",
       " 'shu',\n",
       " 'soused',\n",
       " 'way',\n",
       " 'crêpe',\n",
       " 'dim',\n",
       " 'secret',\n",
       " \"paris's\",\n",
       " 'buco',\n",
       " 'venetian',\n",
       " 'no.ii',\n",
       " 'granita',\n",
       " 'bluewater',\n",
       " 'catalina',\n",
       " 'papa',\n",
       " 'cordials',\n",
       " 'perdu',\n",
       " 'gizzards',\n",
       " 'cargamanto',\n",
       " 'salted',\n",
       " 'cupcakes',\n",
       " 'jasmine',\n",
       " 'flemish',\n",
       " 'hurricane',\n",
       " 'flaky',\n",
       " 'bagel',\n",
       " 'matzoh',\n",
       " 'low',\n",
       " 'pollen',\n",
       " 'todd',\n",
       " 'trifles',\n",
       " 'halloumi',\n",
       " 'felfujt',\n",
       " 'homemade',\n",
       " 'nieve',\n",
       " 'chunk',\n",
       " 'fry',\n",
       " 'curly',\n",
       " \"diane's\",\n",
       " 'moon',\n",
       " 'champagne',\n",
       " 'turnip',\n",
       " 'pears',\n",
       " 'banoffee',\n",
       " 'filling',\n",
       " 'kasu',\n",
       " 'composee',\n",
       " 'cheesy',\n",
       " 'ricciarelli',\n",
       " 'slivered',\n",
       " 'ribbons',\n",
       " 'leafy',\n",
       " 'passover',\n",
       " 'gyro',\n",
       " 'metropolitan',\n",
       " 'dragoon',\n",
       " 'bell',\n",
       " 'semifreddi',\n",
       " 'farls',\n",
       " 'guanciale',\n",
       " 'cookies',\n",
       " 'chock',\n",
       " 'diablo',\n",
       " 'coquito',\n",
       " 'piloncillo',\n",
       " 'twice',\n",
       " 'limonada',\n",
       " 'milk',\n",
       " 'cubano',\n",
       " 'fleur',\n",
       " 'sea',\n",
       " 'uku',\n",
       " 'cheesecakes',\n",
       " 'chayote',\n",
       " 'gobhi',\n",
       " 'manteles',\n",
       " 'romesco',\n",
       " 'aunt',\n",
       " 'plantains',\n",
       " 'garbanzo',\n",
       " 'to',\n",
       " 'sophisticated',\n",
       " 'conch',\n",
       " 'catalana',\n",
       " \"adria's\",\n",
       " \"todd's\",\n",
       " 'decker',\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаем множество на основании слов, которые встречаются в title\n",
    "set_title = set()\n",
    "for i, row in df.iterrows():\n",
    "    title_list = row['title'].lower().replace(',', ' ').replace('-', ' ').replace('(', ' ').replace(')', ' ').replace('\"', ' ').split(' ')\n",
    "    exceptions = ['and', 'with', 'in', 'on', ]\n",
    "    set_title = set_title.union({x for x in title_list if x not in exceptions})\n",
    "set_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e039450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab25278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Предполагаем, что скорее всего можно отнести к ингридиентам те столбцы, в названиях которых встречаются слова из title\n",
    "columns = [col for col in df.columns if col not in set_title]\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a53d6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#В названиях столбцов встречаются названия штатов и крупных городов США, а также названия праздников. Попробуем отсортировать хоть часть из них.\n",
    "list_of_USA_states = ['Alabama', 'Montgomery', 'Birmingham', 'Alaska', 'Juneau', 'Anchorage', 'Arizona', 'Phoenix', 'Arkansas', 'Little Rock', \n",
    "'California', 'Sacramento', 'Los Angeles', 'Colorado', 'Denver', 'Connecticut', 'Hartford', 'Bridgeport', 'Delaware', 'Dover', \n",
    "'Wilmington', 'Florida', 'Tallahassee', 'Jacksonville', 'Georgia', 'Atlanta', 'Hawaii', 'Honolulu', 'Idaho', 'Boise', \n",
    "'Illinois', 'Springfield', 'Chicago', 'Indiana', 'Indianapolis', 'Iowa', 'Des Moines', 'Kansas', 'Topeka', 'Wichita', \n",
    "'Kentucky', 'Frankfort', 'Louisville', 'Louisiana', 'Baton Rouge', 'New Orleans', 'Maine', 'Augusta', 'Portland', 'Maryland', \n",
    "'Annapolis', 'Baltimore', 'Massachusetts', 'Boston', 'Michigan', 'Lansing', 'Detroit', 'Minnesota', 'St. Paul', 'Minneapolis', \n",
    "'Mississippi', 'Jackson', 'Missouri', 'Jefferson City', 'Kansas City', 'Montana', 'Helena', 'Billings', 'Nebraska', 'Lincoln', \n",
    "'Omaha', 'Nevada', 'Carson City', 'Las Vegas', 'New Hampshire', 'Concord', 'Manchester', 'New Jersey', 'Trenton', 'Newark', \n",
    "'New Mexico', 'Santa Fe', 'Albuquerque', 'New York', 'Albany', 'New York', 'North Carolina', 'Raleigh', 'Charlotte', \n",
    "'North Dakota', 'Bismarck', 'Fargo', 'Ohio', 'Columbus', 'Oklahoma', 'Oklahoma City', 'Oregon', 'Salem', 'Portland', \n",
    "'Pennsylvania', 'Harrisburg', 'Philadelphia', 'Rhode Island', 'Providence', 'South Carolina', 'Columbia', 'South Dakota', \n",
    "'Pierre', 'Sioux Falls', 'Tennessee', 'Nashville', 'Memphis', 'Texas', 'Austin', 'Houston', 'Utah', 'Salt Lake City', 'Vermont',\n",
    "'Montpelier', 'Burlington', 'Virginia', 'Richmond', 'Virginia Beach', 'Washington', 'Olympia', 'Seattle', 'West Virginia', \n",
    "'Charleston', 'Wisconsin', 'Madison', 'Milwaukee', 'Wyoming', 'Cheyenne']\n",
    "list_of_USA_states = [x.lower() for x in list_of_USA_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d4999f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Оставляем как ингридиенты те, значения, которых так же нет в list_of_USA_states\n",
    "columns = [col for col in columns if col not in list_of_USA_states]\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be69c0a",
   "metadata": {},
   "source": [
    "Остальные значения придется обработать вручную )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2285b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'rating',\n",
       " 'calories',\n",
       " 'sodium',\n",
       " '#cakeweek',\n",
       " '#wasteless',\n",
       " '22-minute meals',\n",
       " '3-ingredient recipes',\n",
       " '30 days of groceries',\n",
       " 'advance prep required',\n",
       " 'alcoholic',\n",
       " 'anthony bourdain',\n",
       " 'aperitif',\n",
       " 'apple juice',\n",
       " 'asian pear',\n",
       " 'aspen',\n",
       " 'australia',\n",
       " 'back to school',\n",
       " 'backyard bbq',\n",
       " 'bastille day',\n",
       " 'beef rib',\n",
       " 'beef shank',\n",
       " 'beef tenderloin',\n",
       " 'bell pepper',\n",
       " 'beverly hills',\n",
       " 'blue cheese',\n",
       " 'bok choy',\n",
       " 'bon appétit',\n",
       " 'bon app��tit',\n",
       " 'broccoli rabe',\n",
       " 'brown rice',\n",
       " 'brunch',\n",
       " 'brussel sprout',\n",
       " 'bulgaria',\n",
       " 'butternut squash',\n",
       " 'butterscotch/caramel',\n",
       " 'cambridge',\n",
       " 'camping',\n",
       " 'canada',\n",
       " 'candy thermometer',\n",
       " 'casserole/gratin',\n",
       " 'chile pepper',\n",
       " 'christmas eve',\n",
       " 'cinco de mayo',\n",
       " 'cobbler/crumble',\n",
       " 'cocktail party',\n",
       " 'coffee grinder',\n",
       " 'cognac/armagnac',\n",
       " 'collard greens',\n",
       " 'condiment',\n",
       " 'condiment/spread',\n",
       " 'cook like a diner',\n",
       " 'cookbook critic',\n",
       " 'costa mesa',\n",
       " 'cottage cheese',\n",
       " 'cranberry sauce',\n",
       " 'cream cheese',\n",
       " 'créme de cacao',\n",
       " 'cr��me de cacao',\n",
       " 'cuba',\n",
       " 'cupcake',\n",
       " 'dairy free',\n",
       " 'dallas',\n",
       " 'deep-fry',\n",
       " 'digestif',\n",
       " 'diwali',\n",
       " 'dominican republic',\n",
       " 'dorie greenspan',\n",
       " 'double boiler',\n",
       " 'dried fruit',\n",
       " 'eau de vie',\n",
       " 'edible gift',\n",
       " 'egg nog',\n",
       " 'egypt',\n",
       " 'emeril lagasse',\n",
       " 'engagement party',\n",
       " 'entertaining',\n",
       " 'epi + ushg',\n",
       " 'epi loves the microwave',\n",
       " 'family reunion',\n",
       " 'fat free',\n",
       " \"father's day\",\n",
       " 'flaming hot summer',\n",
       " 'flat bread',\n",
       " 'food processor',\n",
       " 'fortified wine',\n",
       " 'fourth of july',\n",
       " 'france',\n",
       " 'frankenrecipe',\n",
       " 'freeze/chill',\n",
       " 'freezer food',\n",
       " 'friendsgiving',\n",
       " 'fritter',\n",
       " 'frozen dessert',\n",
       " 'fruit juice',\n",
       " 'germany',\n",
       " 'goat cheese',\n",
       " 'graduation',\n",
       " 'grand marnier',\n",
       " 'green bean',\n",
       " 'green onion/scallion',\n",
       " 'grill/barbecue',\n",
       " 'ground beef',\n",
       " 'ground lamb',\n",
       " 'guam',\n",
       " 'haiti',\n",
       " 'hanukkah',\n",
       " 'harpercollins',\n",
       " 'healdsburg',\n",
       " 'healthy',\n",
       " 'high fiber',\n",
       " 'hominy/cornmeal/masa',\n",
       " \"hors d'oeuvre\",\n",
       " 'hot drink',\n",
       " 'hot pepper',\n",
       " 'house & garden',\n",
       " 'house cocktail',\n",
       " 'ice cream',\n",
       " 'ice cream machine',\n",
       " 'iced coffee',\n",
       " 'iced tea',\n",
       " 'ireland',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'jam or jelly',\n",
       " 'japan',\n",
       " 'jerusalem artichoke',\n",
       " 'juicer',\n",
       " 'kentucky derby',\n",
       " 'kid-friendly',\n",
       " 'kidney friendly',\n",
       " 'kitchen olympics',\n",
       " 'kosher',\n",
       " 'kosher for passover',\n",
       " 'kwanzaa',\n",
       " 'labor day',\n",
       " 'lamb chop',\n",
       " 'lamb shank',\n",
       " 'lancaster',\n",
       " 'leafy green',\n",
       " 'legume',\n",
       " 'lemon juice',\n",
       " 'lima bean',\n",
       " 'lime juice',\n",
       " 'long beach',\n",
       " 'low cal',\n",
       " 'low carb',\n",
       " 'low cholesterol',\n",
       " 'low fat',\n",
       " 'low sodium',\n",
       " 'low sugar',\n",
       " 'low/no sugar',\n",
       " 'lunar new year',\n",
       " 'lunch',\n",
       " 'macadamia nut',\n",
       " 'macaroni and cheese',\n",
       " 'mandoline',\n",
       " 'maple syrup',\n",
       " 'mardi gras',\n",
       " 'marinate',\n",
       " 'miami',\n",
       " 'milk/cream',\n",
       " 'mixer',\n",
       " 'monterey jack',\n",
       " 'mortar and pestle',\n",
       " \"mother's day\",\n",
       " 'mustard greens',\n",
       " 'nancy silverton',\n",
       " \"new year's day\",\n",
       " \"new year's eve\",\n",
       " 'no meat, no problem',\n",
       " 'no sugar added',\n",
       " 'no-cook',\n",
       " 'non-alcoholic',\n",
       " 'oktoberfest',\n",
       " 'one-pot meal',\n",
       " 'orange juice',\n",
       " 'oscars',\n",
       " 'pacific palisades',\n",
       " 'pan-fry',\n",
       " 'parade',\n",
       " 'pasadena',\n",
       " 'passion fruit',\n",
       " 'pasta maker',\n",
       " 'peanut butter',\n",
       " 'peanut free',\n",
       " 'persian new year',\n",
       " 'peru',\n",
       " 'pescatarian',\n",
       " 'philippines',\n",
       " 'phyllo/puff pastry dough',\n",
       " 'pine nut',\n",
       " 'pittsburgh',\n",
       " 'poach',\n",
       " 'poker/game night',\n",
       " 'pomegranate juice',\n",
       " 'pork chop',\n",
       " 'pork rib',\n",
       " 'pork tenderloin',\n",
       " 'pot pie',\n",
       " 'potato salad',\n",
       " 'potluck',\n",
       " 'poultry sausage',\n",
       " 'pressure cooker',\n",
       " 'purim',\n",
       " 'quick & easy',\n",
       " 'quick and healthy',\n",
       " 'rack of lamb',\n",
       " 'ramadan',\n",
       " 'ramekin',\n",
       " 'red wine',\n",
       " 'root vegetable',\n",
       " 'rosh hashanah/yom kippur',\n",
       " 'salad dressing',\n",
       " 'san francisco',\n",
       " 'sandwich theory',\n",
       " 'santa monica',\n",
       " 'sesame oil',\n",
       " 'shavuot',\n",
       " 'shower',\n",
       " 'simmer',\n",
       " 'skewer',\n",
       " 'slow cooker',\n",
       " 'smoker',\n",
       " 'soufflé/meringue',\n",
       " 'soup/stew',\n",
       " 'sour cream',\n",
       " 'soy free',\n",
       " 'soy sauce',\n",
       " 'spain',\n",
       " 'sparkling wine',\n",
       " 'spirit',\n",
       " 'st. louis',\n",
       " \"st. patrick's day\",\n",
       " 'stir-fry',\n",
       " 'stuffing/dressing',\n",
       " 'sugar conscious',\n",
       " 'sugar snap pea',\n",
       " 'sukkot',\n",
       " 'super bowl',\n",
       " 'suzanne goin',\n",
       " 'sweet potato/yam',\n",
       " 'swiss cheese',\n",
       " 'switzerland',\n",
       " 'tailgating',\n",
       " 'tested & improved',\n",
       " 'tree nut',\n",
       " 'tree nut free',\n",
       " 'triple sec',\n",
       " 'tropical fruit',\n",
       " \"valentine's day\",\n",
       " 'washington, d.c.',\n",
       " 'weelicious',\n",
       " 'westwood',\n",
       " 'wheat/gluten-free',\n",
       " 'white wine',\n",
       " 'whole wheat',\n",
       " 'wild rice',\n",
       " 'windsor',\n",
       " 'yellow squash',\n",
       " 'yonkers',\n",
       " 'cookbooks',\n",
       " 'leftovers',\n",
       " 'snack week']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Список наименований, которых нет в set_title надо проверить вручную, чтобы найти оставшиеся ингридиенты\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f43eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получился список ингридиентов, которые надо оставить, столбец rating - оставляем так как он - target\n",
    "ingridients = ['apple juice',  'asian pear','beef rib', 'beef shank','beef tenderloin','bell pepper','blue cheese',  'bok choy', 'broccoli rabe','brussel sprout', 'butternut squash', 'chile pepper','collard greens','condiment',\n",
    " 'brown rice', 'cottage cheese','cranberry sauce', 'eau de vie', 'egg nog','flat bread','fortified wine',\n",
    " 'cream cheese', 'dried fruit','fritter','fruit juice','goat cheese', 'green bean', 'ground beef',\n",
    " 'créme de cacao','ground lamb',  'hot pepper','ice cream','iced coffee',\n",
    " 'iced tea', 'jam or jelly', 'jerusalem artichoke','lamb chop','leafy green', 'legume', 'lemon juice', 'lima bean','lime juice',\n",
    " 'lamb shank','macadamia nut', 'maple syrup', 'monterey jack', 'mustard greens', 'orange juice',\n",
    " 'passion fruit',  'peanut butter','pine nut', 'pomegranate juice','pork chop',\n",
    " 'pork rib', 'poultry sausage','rack of lamb','red wine','root vegetable','salad dressing','sesame oil',\n",
    " 'pork tenderloin', 'soup/stew', 'sour cream', 'soy sauce', 'sparkling wine', 'sugar snap pea',  'swiss cheese','tree nut', 'triple sec', 'tropical fruit','white wine','whole wheat',\n",
    " 'wild rice', 'yellow squash', 'spirit', 'butterscotch/caramel', 'cognac/armagnac', 'sweet potato/yam', 'milk/cream', \n",
    "              'condiment/spread', 'green onion/scallion', 'hominy/cornmeal/masa', 'phyllo/puff pastry dough',\n",
    "              'soufflé/meringue', 'stuffing/dressing', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "991227d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "#Создаем список названий ингридиентов - те значения, которые есть в set_title и их нет в list_of_USA_states\n",
    "ingridients_1 = [col for col in df.columns if col in set_title]\n",
    "ingridients_1 = [col for col in ingridients_1 if col not in list_of_USA_states]\n",
    "print(len(ingridients_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c319de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#эти названия столбцов убираем их из датасета\n",
    "under_question = ['protein',  'boil','chile','chill','drink','drinks','easter', 'england','fall', 'fat', 'fruit',\n",
    "            'fry','grill', 'london','mexico', 'orzo','paleo', 'paris','party','passover', 'pernod', 'quiche','raw','roast',\n",
    "            'rub','self','steam','stock','summer','thanksgiving','vegan','vegetarian', 'wedding', 'winter','snack', 'fat', \n",
    "            'anniversary', 'bake', 'birthday', 'braise', 'blender', 'halloween', 'jícama', 'kale','kirsch', 'microwave', \n",
    "            'picnic', 'wok', 'breakfast']\n",
    "len(under_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00cb46fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохраняем названия, которых нет в списке under_question - это ингридиенты\n",
    "ingridients_1 = [ing for ing in ingridients_1 if ing not in under_question]\n",
    "len(ingridients_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a80f02d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Столбцы, которые оставим в датасете\n",
    "total_ingridients = ingridients_1 + ingridients\n",
    "len(total_ingridients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b63b8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>almond</th>\n",
       "      <th>amaretto</th>\n",
       "      <th>anchovy</th>\n",
       "      <th>anise</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>apple</th>\n",
       "      <th>apricot</th>\n",
       "      <th>artichoke</th>\n",
       "      <th>arugula</th>\n",
       "      <th>asparagus</th>\n",
       "      <th>...</th>\n",
       "      <th>cognac/armagnac</th>\n",
       "      <th>sweet potato/yam</th>\n",
       "      <th>milk/cream</th>\n",
       "      <th>condiment/spread</th>\n",
       "      <th>green onion/scallion</th>\n",
       "      <th>hominy/cornmeal/masa</th>\n",
       "      <th>phyllo/puff pastry dough</th>\n",
       "      <th>soufflé/meringue</th>\n",
       "      <th>stuffing/dressing</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   almond  amaretto  anchovy  anise  appetizer  apple  apricot  artichoke  \\\n",
       "0     0.0       0.0      0.0    0.0        0.0    1.0      0.0        0.0   \n",
       "1     0.0       0.0      0.0    0.0        0.0    0.0      0.0        0.0   \n",
       "2     0.0       0.0      0.0    0.0        0.0    0.0      0.0        0.0   \n",
       "3     0.0       0.0      0.0    0.0        0.0    0.0      0.0        0.0   \n",
       "4     0.0       0.0      0.0    0.0        0.0    0.0      0.0        0.0   \n",
       "\n",
       "   arugula  asparagus  ...  cognac/armagnac  sweet potato/yam  milk/cream  \\\n",
       "0      0.0        0.0  ...              0.0               0.0         0.0   \n",
       "1      0.0        0.0  ...              0.0               0.0         0.0   \n",
       "2      0.0        0.0  ...              0.0               0.0         0.0   \n",
       "3      0.0        0.0  ...              0.0               0.0         0.0   \n",
       "4      0.0        0.0  ...              0.0               0.0         0.0   \n",
       "\n",
       "   condiment/spread  green onion/scallion  hominy/cornmeal/masa  \\\n",
       "0               0.0                   0.0                   0.0   \n",
       "1               0.0                   0.0                   0.0   \n",
       "2               0.0                   0.0                   0.0   \n",
       "3               0.0                   0.0                   0.0   \n",
       "4               0.0                   0.0                   0.0   \n",
       "\n",
       "   phyllo/puff pastry dough  soufflé/meringue  stuffing/dressing  rating  \n",
       "0                       0.0               0.0                0.0   2.500  \n",
       "1                       0.0               0.0                0.0   4.375  \n",
       "2                       0.0               0.0                0.0   3.750  \n",
       "3                       0.0               0.0                0.0   5.000  \n",
       "4                       0.0               0.0                0.0   3.125  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Датасет, состоящий из ингридиентов\n",
    "df_new = df[total_ingridients]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c335e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20052 entries, 0 to 20051\n",
      "Columns: 396 entries, almond to rating\n",
      "dtypes: float64(396)\n",
      "memory usage: 60.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c862d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведем тип данных столбцов (кроме rating) к int\n",
    "column_names = df_new.columns[:-1]\n",
    "df_new[column_names] = df_new[column_names].astype('int8')\n",
    "df_new['rating'] = pd.to_numeric(df_new['rating'], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1f584c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20052 entries, 0 to 20051\n",
      "Columns: 396 entries, almond to rating\n",
      "dtypes: float32(1), int8(395)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa30de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2134"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка на полные дубликаты\n",
    "df_new.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71da3b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление дубликатоов\n",
    "df_new = df_new.drop_duplicates(keep='first')\n",
    "df_new.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "209d6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняем датафрейм в файл\n",
    "df_new.to_csv('./data/ingridients.csv', index=False, compression={'method':'zip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93497460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяем датасет на test и trein\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new.drop('rating', axis=1), df_new.rating, stratify=df_new.rating,\n",
    "                                                    test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "560e525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#очистка памяти\n",
    "%reset_selective -f \"^df$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac1738",
   "metadata": {},
   "source": [
    "### 1.2 Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa40ad",
   "metadata": {},
   "source": [
    "Для прогнозирования рейтинга попробуем различные алгоритмы и их гиперпараметры. Выберем лучшее решение на основе gridsearch и кроссвалидации и оценим RMSE на тестовой подвыборке.  \n",
    "\n",
    "Посчитаем RMSE для наивного регрессора, в котором просто высчитали средний рейтинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a773808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelselection(grids, grid_dict):\n",
    "    \n",
    "    \"\"\"Принимает на вход список экземпляров GridSearchCV и словарь, в котором ключами являются индексы из этого списка, \n",
    "    а значениями – названия моделей. Возвращает лучшую модель в своем классе, ее результат на тестовой \n",
    "    выборке \"\"\"\n",
    "    \n",
    "    evaluations=[]\n",
    "    \n",
    "    for i in range(len(grids)):\n",
    "        grids[i].fit(X_train, y_train)\n",
    "        score_test = grids[i].score(X_test, y_test)\n",
    "        evaluations.append(grids[i].best_score_)\n",
    "            \n",
    "        print('Estimator:', grid_dict[i])\n",
    "        print('Best params:', grids[i].best_params_)\n",
    "        print('Best score: ', grids[i].best_score_)\n",
    "        print('Best test score: ', score_test)\n",
    "        print()\n",
    "            \n",
    "    return print('Best estimator:', grid_dict[evaluations.index(max(evaluations))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a144566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список экземпляров GridSearchCV\n",
    "\n",
    "#LinearRegression\n",
    "params = {'fit_intercept':[True,False],  \n",
    "          'copy_X':[True, False]}\n",
    "gs_lr = GridSearchCV(LinearRegression(), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                     scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#DecisionTreeRegressor\n",
    "params = {'max_depth':[i for i in range(4, 10, 2)],\n",
    "         'min_samples_split':[i for i in range(2, 4)],\n",
    "          'min_samples_leaf':[i for i in range(2, 5)]\n",
    "         }\n",
    "gs_tree = GridSearchCV(DecisionTreeRegressor(random_state=21), params, error_score='raise', n_jobs=-1, \n",
    "                       cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#RandomForestRegressor\n",
    "params = {'n_estimators':[5, 10, 15, 20, 30, 50, 100, 150], \n",
    "          'max_depth':[i for i in range(4, 12, 2)],\n",
    "          'min_samples_split':[i for i in range(2, 5)],\n",
    "          'min_samples_leaf':[i for i in range(1, 5)]\n",
    "         }\n",
    "gs_rf = GridSearchCV(RandomForestRegressor(random_state=21), params, error_score='raise', n_jobs=-1, \n",
    "                       cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#GradientBoostingRegressor\n",
    "params = {'learning_rate': [0.01, 0.05],\n",
    "          'n_estimators' : [50, 100, 150],\n",
    "          'max_depth'    : [4,6,8],\n",
    "          'min_samples_split' : [i for i in range(2, 5)],\n",
    "          'min_samples_leaf' : [i for i in range(1, 5)],\n",
    "                 }\n",
    "gs_gbr = GridSearchCV(GradientBoostingRegressor(random_state=21), params, error_score='raise', n_jobs=-1, \n",
    "                       cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#SVR\n",
    "params = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "          'C' : [1,5,10],\n",
    "          'degree' : [3,8],\n",
    "          'gamma' : ('auto','scale')}\n",
    "gs_svr = GridSearchCV(SVR(), params, error_score='raise', n_jobs=-1, cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grids = [gs_lr, gs_tree, gs_rf, gs_gbr, gs_svr ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "991aff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь с названиями моделей\n",
    "grid_dict = {0:'LinearRegression', 1:'DecisionTreeRegressor', 2:'RandomForestRegressor', 3:'GradientBoostingRegressor', 4:'SVR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d95697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LinearRegression\n",
      "Best params: {'copy_X': True, 'fit_intercept': True}\n",
      "Best score:  -63913268814.17646\n",
      "Best test score:  -1002564779098.9299\n",
      "\n",
      "Estimator: DecisionTreeRegressor\n",
      "Best params: {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best score:  -1.2834451375344054\n",
      "Best test score:  -1.2811137366561487\n",
      "\n",
      "Estimator: RandomForestRegressor\n",
      "Best params: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best score:  -1.264673216661259\n",
      "Best test score:  -1.2599552926913014\n",
      "\n",
      "Estimator: GradientBoostingRegressor\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best score:  -1.2587524087384694\n",
      "Best test score:  -1.254072298508256\n",
      "\n",
      "Estimator: SVR\n",
      "Best params: {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score:  -1.293084321773685\n",
      "Best test score:  -1.282169590536687\n",
      "\n",
      "Best estimator: GradientBoostingRegressor\n"
     ]
    }
   ],
   "source": [
    "modelselection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "889518a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Список экземпляров GridSearchCV для ансамблей\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.05, max_depth=6, min_samples_split=4,\n",
    "                          n_estimators=150, random_state=21)\n",
    "rf = RandomForestRegressor(max_depth=10, min_samples_leaf=4, n_estimators=150,\n",
    "                      random_state=21)\n",
    "svr = SVR(C=1)\n",
    "\n",
    "#VotingRegressor\n",
    "params = {'weights': [(1, 1, 1), (2, 1, 1), (1, 2, 1), (1, 1, 2), (2, 2, 1), (1, 2, 2), (2, 1, 2), (3, 2, 1), (1, 3, 2), \n",
    "                      (2, 1, 3), (3, 1, 2)]\n",
    "         }\n",
    "gs_vr = GridSearchCV(VotingRegressor(estimators=[('gbr', gbr), ('rf', rf), ('svr', svr)]), params, error_score='raise', \n",
    "                     n_jobs=-1, cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#BaggingRegressor\n",
    "params = {'base_estimator': [None, gbr, svr, rf],\n",
    "          'n_estimators': [5, 10, 15]\n",
    "}\n",
    "gs_br = GridSearchCV(BaggingRegressor(), params, error_score='raise', n_jobs=-1, cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#StackingRegressor\n",
    "params = {'passthrough': [True, False],\n",
    "          'final_estimator': [gbr, rf, svr, None]}\n",
    "gs_sr = GridSearchCV(StackingRegressor(estimators=[('gbr', gbr), ('rf', rf), ('svr', svr)]), params, error_score='raise', \n",
    "                     n_jobs=-1, cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grids = [gs_vr, gs_br, gs_sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8babc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь с названиями моделей\n",
    "grid_dict = {0:'VotingRegressor', 1:'BaggingRegressor', 2:'StackingRegressor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ddb6d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: VotingRegressor\n",
      "Best params: {'weights': (2, 1, 1)}\n",
      "Best score:  -1.257745668747706\n",
      "Best test score:  -1.2501523123522564\n",
      "\n",
      "Estimator: BaggingRegressor\n",
      "Best params: {'base_estimator': GradientBoostingRegressor(learning_rate=0.05, max_depth=6, min_samples_split=4,\n",
      "                          n_estimators=150, random_state=21), 'n_estimators': 15}\n",
      "Best score:  -1.255572997696328\n",
      "Best test score:  -1.2514304121452255\n",
      "\n",
      "Estimator: StackingRegressor\n",
      "Best params: {'final_estimator': None, 'passthrough': True}\n",
      "Best score:  -1.249622975471454\n",
      "Best test score:  -1.244102128369942\n",
      "\n",
      "Best estimator: StackingRegressor\n"
     ]
    }
   ],
   "source": [
    "modelselection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7327ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE наивного регрессора: 1.3166418859981708\n"
     ]
    }
   ],
   "source": [
    "#Посчитайте RMSE для наивного регрессора, в котором вы просто высчитали средний рейтинг.\n",
    "dummy = DummyRegressor(strategy=\"constant\", constant=df_new.rating.mean())\n",
    "dummy.fit(df_new.drop('rating', axis=1), df_new.rating)\n",
    "dummy_pred = dummy.predict(df_new.rating)\n",
    "\n",
    "print(f'RMSE наивного регрессора: {mean_squared_error(dummy_pred, df_new.rating, squared=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7483b4",
   "metadata": {},
   "source": [
    "Выводы: Лучшие результаты показал ансамбль StackingRegressor, RMSE на test - 1.24, что немного лучше наивного регрессора (1.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206258a",
   "metadata": {},
   "source": [
    "### 1.3 Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b7034",
   "metadata": {},
   "source": [
    "Бинаризируем значения целевой переменной путем округления рейтингов до ближайшего целого числа. Это и будут классы.\n",
    "\n",
    "Для прогнозирования классов попробуем различные алгоритмы и их гиперпараметры. Выберем лучшее решение на основе gridsearch и кроссвалидации и посчитаем accuracy на тестовой подвыборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5196c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Бинаризируйте значения целевой переменной\n",
    "y_train =  round(y_train, 0)\n",
    "y_test = round(y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c29fdc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список экземпляров GridSearchCV\n",
    "\n",
    "#LogisticRegression\n",
    "params = [{'solver' : ['saga'],\n",
    "      'penalty' : ['l1', 'l2', 'none'],\n",
    "      'fit_intercept' : [True, False],\n",
    "      'C' : [0.01, 0.1, 1],\n",
    "      'class_weight':['balanced', None]},\n",
    "    {'solver' : ['newton-cg', 'lbfgs'],\n",
    "      'penalty' : ['l2','none'],\n",
    "      'fit_intercept' : [True, False],\n",
    "      'C' : [0.01, 0.1, 1],\n",
    "      'class_weight':['balanced', None],}\n",
    "    ]\n",
    "gs_logreg = GridSearchCV(LogisticRegression(), params, error_score='raise', n_jobs=-1, cv=3, scoring='accuracy')\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "params = {'max_depth':[i for i in range(4, 10, 2)],\n",
    "         'min_samples_split':[i for i in range(2, 4)],\n",
    "          'min_samples_leaf':[i for i in range(2, 5)],\n",
    "          'criterion':['gini', 'entropy']\n",
    "         }\n",
    "gs_clf_tree = GridSearchCV(DecisionTreeClassifier(random_state=21), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                           scoring='accuracy')\n",
    "\n",
    "#RandomForestClassifier\n",
    "params = {'n_estimators':[5, 10, 15, 20, 30, 50, 100, 150], \n",
    "          'max_depth':[i for i in range(4, 12, 2)],\n",
    "          'min_samples_split':[i for i in range(2, 5)],\n",
    "          'min_samples_leaf':[i for i in range(1, 5)]\n",
    "         }\n",
    "gs_clf_rf = GridSearchCV(RandomForestClassifier(random_state=21), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                           scoring='accuracy')\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "params = {'learning_rate': [0.01, 0.05],\n",
    "          'n_estimators' : [50, 100, 150],\n",
    "          'max_depth'    : [4,6,8],\n",
    "          'min_samples_split' : [i for i in range(2, 4)],\n",
    "          'min_samples_leaf' : [i for i in range(1, 4)],\n",
    "                 }\n",
    "gs_clf_xgb = GridSearchCV(GradientBoostingClassifier(random_state=21), params, error_score='raise', n_jobs=-1, \n",
    "                          cv=3, scoring='accuracy')\n",
    "\n",
    "#SVC\n",
    "params = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "          'C' : [1,5,10],\n",
    "          'degree' : [3,8],\n",
    "          'gamma' : ('auto','scale')\n",
    "         }\n",
    "gs_clf_svc = GridSearchCV(SVC(), params, error_score='raise', n_jobs=-1, cv=3, scoring='accuracy')\n",
    "\n",
    "grids = [gs_logreg, gs_clf_tree, gs_clf_rf, gs_clf_xgb, gs_clf_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5728cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь с названиями моделей\n",
    "grid_dict = {0:'LogisticRegression', 1:'DecisionTreeClassifier', 2:'RandomForestClassifier', 3:'GradientBoostingClassifier', \n",
    "             4:'SVC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "886b3b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LogisticRegression\n",
      "Best params: {'C': 0.1, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best score:  0.6785265801590623\n",
      "Best test score:  0.677734375\n",
      "\n",
      "Estimator: DecisionTreeClassifier\n",
      "Best params: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Best score:  0.6739221431561323\n",
      "Best test score:  0.6746651785714286\n",
      "\n",
      "Estimator: RandomForestClassifier\n",
      "Best params: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best score:  0.6723873308218223\n",
      "Best test score:  0.6732700892857143\n",
      "\n",
      "Estimator: GradientBoostingClassifier\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score:  0.6744104925352309\n",
      "Best test score:  0.6780133928571429\n",
      "\n",
      "Estimator: SVC\n",
      "Best params: {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score:  0.6771312962187804\n",
      "Best test score:  0.6788504464285714\n",
      "\n",
      "Best estimator: SVC\n"
     ]
    }
   ],
   "source": [
    "modelselection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b85a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наивного классификатора: 0.6665736607142857\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем accuracy наивного классификатора\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=21)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_pred = dummy_clf.predict(y_test)\n",
    "\n",
    "print(f'Accuracy наивного классификатора: {accuracy_score(y_test, dummy_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba869b1",
   "metadata": {},
   "source": [
    "Выводы: Лучшая модель - SVC, accuracy на test - 67.9%, что всего на 1% лучше наивного классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4359a8",
   "metadata": {},
   "source": [
    "Снова проведем бинаризацию целевого столбца, преобразовав теперь целые числа в классы bad (0, 1) (невкусное), so-so (2, 3) (нормальное), great (4, 5) (вкусное).\n",
    "\n",
    "Снова для прогнозирования классов попробуем различные алгоритмы и их гиперпараметры. Выберем лучшее решение на основе кроссвалидации и посчитаем accuracy на тестовой подвыборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70769f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проведем бинаризацию, преобразовав теперь целые числа в классы bad (0, 1) (невкусное), so-so (2, 3) (нормальное), great (4, 5) (вкусное).\n",
    "bins = [0, 1, 3, 5]\n",
    "labels = ['bad', 'so-so', 'great']\n",
    "y_test = pd.cut(y_test, bins=bins, labels=labels, include_lowest=True)\n",
    "y_train = pd.cut(y_train, bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea89b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LogisticRegression\n",
      "Best params: {'C': 0.1, 'class_weight': None, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best score:  0.8034742570113019\n",
      "Best test score:  0.8035714285714286\n",
      "\n",
      "Estimator: DecisionTreeClassifier\n",
      "Best params: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best score:  0.8011022743128228\n",
      "Best test score:  0.8018973214285714\n",
      "\n",
      "Estimator: RandomForestClassifier\n",
      "Best params: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}\n",
      "Best score:  0.7996372261755268\n",
      "Best test score:  0.8002232142857143\n",
      "\n",
      "Estimator: GradientBoostingClassifier\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best score:  0.8024277940560904\n",
      "Best test score:  0.8030133928571429\n",
      "\n",
      "Estimator: SVC\n",
      "Best params: {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score:  0.80361378540533\n",
      "Best test score:  0.8055245535714286\n",
      "\n",
      "Best estimator: SVC\n"
     ]
    }
   ],
   "source": [
    "#Снова для прогнозирования классов попробуйте различные алгоритмы и их гиперпараметры.\n",
    "modelselection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "98b5d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наивного классификатора: 0.7965959821428571\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем accuracy наивного классификатора\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=21)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_pred = dummy_clf.predict(y_test)\n",
    "\n",
    "print(f'Accuracy наивного классификатора: {accuracy_score(y_test, dummy_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5682a9",
   "metadata": {},
   "source": [
    "Вывод: Лучшая модель по прежнему SVC, accuracy на test - 80.6%. Но accuracy наивного классификатора 79.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cd468",
   "metadata": {},
   "source": [
    "Что хуже: спрогнозировать плохой рейтинг, который на самом деле окажется хорошим, или спрогнозировать хороший рейтинг, который на самом деле окажется плохим? Заменим метрику accuracy другой соответствующей метрикой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972245c",
   "metadata": {},
   "source": [
    "Хуже спрогнозировать хороший рейтинг, который окажется плохим. Будем для оценки использовать метрику precision. Именно введение precision не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. Цель precision – классифицировать все Positive семплы как Positive, не допуская ложных определений Negative как Positive:\n",
    "\n",
    "$\\large precision = \\frac{TP}{TP + FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785dfe5",
   "metadata": {},
   "source": [
    "Для прогнозирования классов с новой метрикой попробуем различные алгоритмы и их гиперпараметры. Выберем лучшее решение и посчитаем метрику на тестовой подвыборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "100ce311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для прогноза с новой метрикой воспользуемся make_scorer\n",
    "\n",
    "custom_scorer = make_scorer(precision_score, average=\"weighted\", zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f5cff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список экземпляров GridSearchCV\n",
    "\n",
    "#LogisticRegression\n",
    "params = {'solver' : ['saga'],\n",
    "      'penalty' : ['elasticnet'],\n",
    "      'fit_intercept' : [True, False],\n",
    "      'C' : [0.01, 0.1, 1],\n",
    "      'class_weight':['balanced', None],\n",
    "          'l1_ratio': [0.2, 0.4, 0.6, 0.8]}\n",
    "\n",
    "gs_logreg = GridSearchCV(LogisticRegression(), params, error_score='raise', n_jobs=-1, cv=3, scoring=custom_scorer)\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "params = {'max_depth':[i for i in range(4, 10, 2)],\n",
    "         'min_samples_split':[i for i in range(2, 4)],\n",
    "          'min_samples_leaf':[i for i in range(2, 5)],\n",
    "          'criterion':['gini', 'entropy']\n",
    "         }\n",
    "gs_clf_tree = GridSearchCV(DecisionTreeClassifier(random_state=21), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                           scoring=custom_scorer)\n",
    "\n",
    "#RandomForestClassifier\n",
    "params = {'n_estimators':[50, 100, 150], \n",
    "          'max_depth':[i for i in range(6, 10, 2)],\n",
    "          'min_samples_split':[i for i in range(2, 5)],\n",
    "          'min_samples_leaf':[i for i in range(1, 5)],\n",
    "          'bootstrap': [True, False]\n",
    "         }\n",
    "gs_clf_rf = GridSearchCV(RandomForestClassifier(random_state=21), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                           scoring=custom_scorer)\n",
    "\n",
    "#GradientBoostingClassifier(random_state=21)\n",
    "params = {'learning_rate': [0.01, 0.05],\n",
    "          'n_estimators' : [100, 150],\n",
    "          'max_depth'    : [6, 8],\n",
    "          'min_samples_split' : [i for i in range(2, 4)],\n",
    "          'min_samples_leaf' : [i for i in range(2, 4)],\n",
    "                 }\n",
    "gs_clf_xgb = GridSearchCV(GradientBoostingClassifier(random_state=21), params, error_score='raise', n_jobs=-1, cv=3, \n",
    "                                scoring=custom_scorer)\n",
    "\n",
    "#SVC\n",
    "params = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "          'C' : [1,5,10],\n",
    "          'degree' : [3,8],\n",
    "          'gamma' : ('auto','scale')\n",
    "         }\n",
    "gs_clf_svc = GridSearchCV(SVC(), params, error_score='raise', n_jobs=-1, cv=3, scoring=custom_scorer)\n",
    "\n",
    "grids = [gs_logreg, gs_clf_tree, gs_clf_rf, gs_clf_xgb, gs_clf_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "650e7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь с названиями моделей\n",
    "grid_dict = {0:'LogisticRegression', 1:'DecisionTreeClassifier', 2:'RandomForestClassifier', 3:'GradientBoostingClassifier', \n",
    "             4:'SVC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0707bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: LogisticRegression\n",
      "Best params: {'C': 0.1, 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.2, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "Best score:  0.719958790226292\n",
      "Best test score:  0.729981960857308\n",
      "\n",
      "Estimator: DecisionTreeClassifier\n",
      "Best params: {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Best score:  0.7081627271690647\n",
      "Best test score:  0.6967656550853726\n",
      "\n",
      "Estimator: RandomForestClassifier\n",
      "Best params: {'bootstrap': True, 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Best score:  0.7226769913437016\n",
      "Best test score:  0.7151592372118636\n",
      "\n",
      "Estimator: GradientBoostingClassifier\n",
      "Best params: {'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score:  0.7390416397961834\n",
      "Best test score:  0.708326578955168\n",
      "\n",
      "Estimator: SVC\n",
      "Best params: {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best score:  0.7198989077110646\n",
      "Best test score:  0.735696176966128\n",
      "\n",
      "Best estimator: GradientBoostingClassifier\n"
     ]
    }
   ],
   "source": [
    "modelselection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650fdb9",
   "metadata": {},
   "source": [
    "### 1.4 Принятие решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6a682",
   "metadata": {},
   "source": [
    "Выводы: Лучшая модель - GradientBoostingClassifier с precision 73.9%, ее будем использовать дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a289e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_reg.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохранение лучшей модели регрессора\n",
    "estimators = [\n",
    "    ('gbr', GradientBoostingRegressor(learning_rate=0.05, max_depth=6, min_samples_split=4,\n",
    "                          n_estimators=150, random_state=21)),\n",
    "    ('rf', RandomForestRegressor(max_depth=10, min_samples_leaf=4, n_estimators=150,\n",
    "                      random_state=21)),\n",
    "    ('svr', SVR(C=1))]\n",
    "\n",
    "best_model_reg = StackingRegressor(estimators = estimators, final_estimator=None, passthrough=True).fit(X_train, y_train) \n",
    "\n",
    "joblib.dump(best_model_reg, 'best_model_reg.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bc3e63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_clf.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохранение лучшей модели классификатора \n",
    "\n",
    "best_model_clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=6, min_samples_leaf=2, \n",
    "                             min_samples_split=2, n_estimators=100, random_state=21).fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(best_model_clf, 'best_model_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ee7fb",
   "metadata": {},
   "source": [
    "## 2. Пищевая ценность"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947bd7d",
   "metadata": {},
   "source": [
    "Соберем в датафрейм всю информацию о пищевой ценности продуктов из подготовленного и отфильтрованного набора данных (только столбцы с продуктами). Используйте для этого API.\n",
    "\n",
    "Конвертируем все значения в % от суточной нормы потребления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bc4e0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nutrient</th>\n",
       "      <th>Unit of measure</th>\n",
       "      <th>Adults and Children ≥ 4 years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vitamin A</td>\n",
       "      <td>Micrograms RAE2 (mcg)</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vitamin C</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calcium</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iron</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vitamin D</td>\n",
       "      <td>Micrograms (mcg)3</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vitamin E</td>\n",
       "      <td>Milligrams (mg)4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vitamin K</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thiamin</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Riboflavin</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Niacin</td>\n",
       "      <td>Milligrams NE5 (mg)</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vitamin B6</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Folate</td>\n",
       "      <td>Micrograms DFE7 (mcg)</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vitamin B12</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Biotin</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pantothenic acid</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Phosphorus</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iodine</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Magnesium</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zinc</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Selenium</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Copper</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Manganese</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chromium</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Molybdenum</td>\n",
       "      <td>Micrograms (mcg)</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chloride</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Potassium</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>4700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Choline</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fat</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Saturated fat</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Total carbohydrates</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sodium</td>\n",
       "      <td>Milligrams (mg)</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dietary Fiber</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Protein</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Added sugars</td>\n",
       "      <td>Grams (g)</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Nutrient        Unit of measure  Adults and Children ≥ 4 years\n",
       "0             Vitamin A  Micrograms RAE2 (mcg)                          900.0\n",
       "1             Vitamin C        Milligrams (mg)                           90.0\n",
       "2               Calcium        Milligrams (mg)                         1300.0\n",
       "3                  Iron        Milligrams (mg)                           18.0\n",
       "4             Vitamin D      Micrograms (mcg)3                           20.0\n",
       "5             Vitamin E       Milligrams (mg)4                           15.0\n",
       "6             Vitamin K       Micrograms (mcg)                          120.0\n",
       "7               Thiamin        Milligrams (mg)                            1.2\n",
       "8            Riboflavin        Milligrams (mg)                            1.3\n",
       "9                Niacin    Milligrams NE5 (mg)                           16.0\n",
       "10           Vitamin B6        Milligrams (mg)                            1.7\n",
       "11               Folate  Micrograms DFE7 (mcg)                          400.0\n",
       "12          Vitamin B12       Micrograms (mcg)                            2.4\n",
       "13               Biotin       Micrograms (mcg)                           30.0\n",
       "14     Pantothenic acid        Milligrams (mg)                            5.0\n",
       "15           Phosphorus        Milligrams (mg)                         1250.0\n",
       "16               Iodine       Micrograms (mcg)                          150.0\n",
       "17            Magnesium        Milligrams (mg)                          420.0\n",
       "18                 Zinc        Milligrams (mg)                           11.0\n",
       "19             Selenium       Micrograms (mcg)                           55.0\n",
       "20               Copper        Milligrams (mg)                            0.9\n",
       "21            Manganese        Milligrams (mg)                            2.3\n",
       "22             Chromium       Micrograms (mcg)                           35.0\n",
       "23           Molybdenum       Micrograms (mcg)                           45.0\n",
       "24             Chloride        Milligrams (mg)                         2300.0\n",
       "25            Potassium        Milligrams (mg)                         4700.0\n",
       "26              Choline        Milligrams (mg)                          550.0\n",
       "27                  Fat              Grams (g)                           78.0\n",
       "28        Saturated fat              Grams (g)                           20.0\n",
       "29          Cholesterol        Milligrams (mg)                          300.0\n",
       "30  Total carbohydrates              Grams (g)                          275.0\n",
       "31               Sodium        Milligrams (mg)                         2300.0\n",
       "32        Dietary Fiber              Grams (g)                           28.0\n",
       "33              Protein              Grams (g)                           50.0\n",
       "34         Added sugars              Grams (g)                           50.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Прочитаем список нутриентов, которые необходимо конвертировать в % от суточной нормы потребления. \n",
    "must_nutrients = pd.read_csv('./data/daily values.csv')\n",
    "must_nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02808300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняем информацию по нутриентам из апи в список\n",
    "\n",
    "dict_col=[]\n",
    "col_names = []\n",
    "\n",
    "for col in df_new.columns:\n",
    "    url_search = f'https://api.nal.usda.gov/fdc/v1/foods/search?query={col}&api_key=S0MlcT2g7gaK9H3ifNoupHuaecg1ZxTI7hC5csF4'\n",
    "    data_search = requests.get(url_search).json()\n",
    "    try:\n",
    "        foodNutrients = data_search['foods'][0]['foodNutrients']\n",
    "        col_names.append(col)\n",
    "        \n",
    "        for i in range(len(foodNutrients)):\n",
    "            col_values = []\n",
    "            col_values.append(col)\n",
    "            col_values.append(foodNutrients[i]['nutrientName'])\n",
    "            col_values.append(foodNutrients[i]['value'])\n",
    "            col_values.append(foodNutrients[i]['unitName'])\n",
    "            dict_col.append(col_values)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e51a32c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>nutrient_name</th>\n",
       "      <th>value</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almond</td>\n",
       "      <td>Protein</td>\n",
       "      <td>21.0</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almond</td>\n",
       "      <td>Total lipid (fat)</td>\n",
       "      <td>55.5</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almond</td>\n",
       "      <td>Carbohydrate, by difference</td>\n",
       "      <td>18.8</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almond</td>\n",
       "      <td>Energy</td>\n",
       "      <td>614.0</td>\n",
       "      <td>KCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>almond</td>\n",
       "      <td>Alcohol, ethyl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item                nutrient_name  value unit_name\n",
       "0  almond                      Protein   21.0         G\n",
       "1  almond            Total lipid (fat)   55.5         G\n",
       "2  almond  Carbohydrate, by difference   18.8         G\n",
       "3  almond                       Energy  614.0      KCAL\n",
       "4  almond               Alcohol, ethyl    0.0         G"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#преобразуем полученные данные в датафрейм\n",
    "data_nutrients = pd.DataFrame(dict_col, columns=['item', 'nutrient_name', 'value', 'unit_name'])\n",
    "data_nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "21f081e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведем все к нижнему регистру\n",
    "must_nutrients['Nutrient']=must_nutrients['Nutrient'].str.lower()\n",
    "data_nutrients['nutrient_name'] = data_nutrients['nutrient_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2365d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вручную сопоставим названия нутриентов  из must_nutrients и data_nutrients\n",
    "nutr_uniq = {\n",
    "    'vitamin a':'vitamin a, rae',\n",
    "    'vitamin c':'vitamin c, total ascorbic acid',\n",
    "    'calcium':'calcium, ca',\n",
    "    'iron': 'iron, fe',\n",
    "    'vitamin d':'vitamin d (d2 + d3)', \n",
    "    'vitamin e': 'vitamin e (alpha-tocopherol)',\n",
    "    'vitamin k': 'vitamin k (phylloquinone)',\n",
    "    'thiamin':'thiamin',\n",
    "    'riboflavin': 'riboflavin',\n",
    "    'niacin': 'niacin',\n",
    "    'folate': 'folate, total',\n",
    "    'biotin': 'biotin',\n",
    "    'pantothenic acid': 'pantothenic acid',\n",
    "    'phosphorus': 'phosphorus, p',\n",
    "    'magnesium': 'magnesium, mg',\n",
    "    'zinc': 'zinc, zn',\n",
    "    'selenium': 'selenium, se',\n",
    "    'copper': 'copper, cu',\n",
    "    'manganese': 'manganese, mn',\n",
    "    'potassium': 'potassium, k',\n",
    "    'choline': 'choline, total',\n",
    "    'fat': 'total lipid (fat)',\n",
    "    'saturated fat': 'fatty acids, total saturated',\n",
    "    'cholesterol': 'cholesterol',\n",
    "    'sodium': 'sodium, na',\n",
    "    'dietary fiber': 'fiber, total dietary',\n",
    "    'protein': 'protein',\n",
    "    'added sugars': 'sugars, added'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "8fc05afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(value):\n",
    "    for k, v in nutr_uniq.items():\n",
    "        if v == value:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d1b905fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['protein', 'fat', None, 'dietary fiber', 'calcium', 'iron',\n",
       "       'magnesium', 'phosphorus', 'potassium', 'sodium', 'zinc', 'copper',\n",
       "       'selenium', 'vitamin a', 'vitamin e', 'vitamin d', 'vitamin c',\n",
       "       'thiamin', 'riboflavin', 'niacin', 'folate', 'choline',\n",
       "       'vitamin k', 'cholesterol', 'saturated fat', 'added sugars',\n",
       "       'pantothenic acid', 'manganese', 'biotin'], dtype=object)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Заменим значения столбца nutrient_name на соответствующие им ключи словаря nutr_uniq\n",
    "data_nutrients['nutrient_name'] = data_nutrients['nutrient_name'].apply(get_key)\n",
    "data_nutrients['nutrient_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "42e2932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['protein', 'fat', 'dietary fiber', 'calcium', 'iron', 'magnesium',\n",
       "       'phosphorus', 'potassium', 'sodium', 'zinc', 'copper', 'selenium',\n",
       "       'vitamin a', 'vitamin e', 'vitamin d', 'vitamin c', 'thiamin',\n",
       "       'riboflavin', 'niacin', 'folate', 'choline', 'vitamin k',\n",
       "       'cholesterol', 'saturated fat', 'added sugars', 'pantothenic acid',\n",
       "       'manganese', 'biotin'], dtype=object)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Оставим в датасете только те строки, нутриенты которых есть в словаре\n",
    "data_nutrients = data_nutrients.loc[data_nutrients['nutrient_name'].isin(nutr_uniq.keys())].reset_index(drop=True)\n",
    "data_nutrients['nutrient_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "806728f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим единицы измерения, совпадают ли они в обоих датафреймах\n",
    "def un_nu(name):\n",
    "    un = must_nutrients.loc[must_nutrients['Nutrient']==name, 'Unit of measure']\n",
    "    try:\n",
    "        ind1=str(un).index('(')\n",
    "        ind2=str(un).index(')')\n",
    "        un = str(un)[ind1+1:ind2]\n",
    "        return un\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7665fa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>nutrient_name</th>\n",
       "      <th>value</th>\n",
       "      <th>unit_name</th>\n",
       "      <th>Unit of measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [item, nutrient_name, value, unit_name, Unit of measure]\n",
       "Index: []"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Единицы измерения совпадают, так как UG==mcg\n",
    "data_nutrients['Unit of measure'] = data_nutrients['nutrient_name'].apply(un_nu)\n",
    "data_nutrients.loc[data_nutrients['unit_name']=='UG', 'unit_name'] = 'mcg'\n",
    "\n",
    "data_nutrients.loc[data_nutrients['unit_name'].str.lower()!=data_nutrients['Unit of measure'].str.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c403903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#переведем значения столбца value в % от суточной нормы. \n",
    "def day_norm(row):\n",
    "    name = row['nutrient_name']\n",
    "    value = row['value']\n",
    "    norm = must_nutrients.loc[must_nutrients['Nutrient']==name, 'Adults and Children ≥ 4 years']\n",
    "    new_value = float(value)/float(norm)*100\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c78e7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удалим ненужные столбцы\n",
    "data_nutrients['daily_value'] = data_nutrients.apply(day_norm, axis=1)\n",
    "data_nutrients.drop(['value', 'value', 'unit_name', 'Unit of measure'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3b7be26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>nutrient_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almond</td>\n",
       "      <td>thiamin</td>\n",
       "      <td>3.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almond</td>\n",
       "      <td>sodium</td>\n",
       "      <td>9.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almond</td>\n",
       "      <td>selenium</td>\n",
       "      <td>4.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almond</td>\n",
       "      <td>saturated fat</td>\n",
       "      <td>32.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>almond</td>\n",
       "      <td>riboflavin</td>\n",
       "      <td>72.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item  nutrient_name      value\n",
       "0  almond        thiamin   3.416667\n",
       "1  almond         sodium   9.869565\n",
       "2  almond       selenium   4.363636\n",
       "3  almond  saturated fat  32.750000\n",
       "4  almond     riboflavin  72.230769"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохраним датафрейм\n",
    "nutrients_daily_value.to_csv('./data/nutrients_daily_value.csv', index=False)\n",
    "dff = pd.read_csv('./data/nutrients_daily_value.csv')\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ec8f7",
   "metadata": {},
   "source": [
    "## 3. Похожие рецепты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a3dd4",
   "metadata": {},
   "source": [
    "Для каждого рецепта из набора данных найдем ссылку на сайте epicurious.com и подробную информацию о нем (название рецепта, рейтинг на платформе и URl). Если сделать это не удалось, найдем для данного рецепта похожую ссылку в Интернете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4b635026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  rating  calories  protein  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
       "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
       "\n",
       "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
       "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
       "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
       "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
       "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
       "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
       "\n",
       "   ...  yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  \\\n",
       "0  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "1  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "2  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "3  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "4  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "\n",
       "   snack  snack week  turkey  \n",
       "0    0.0         0.0     1.0  \n",
       "1    0.0         0.0     0.0  \n",
       "2    0.0         0.0     0.0  \n",
       "3    0.0         0.0     0.0  \n",
       "4    0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузим снова датасет\n",
    "df = pd.read_csv('./data/epi_r.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9c55c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удалим полные дубликаты и дубликаты в столбце title\n",
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0be0eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.title.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "958d8b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "17736\n"
     ]
    }
   ],
   "source": [
    "#Окончательный список без дубликатов\n",
    "titles = df.title\n",
    "titles = titles.drop_duplicates()\n",
    "print(titles.duplicated().sum())\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1c551a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17736"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['title'], keep='first').reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5db177af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url_rating(title):\n",
    "    \n",
    "    \"\"\"Функция принимает на вход название рецепта и возвращает его рейтинг и ссылку на сайте epicurious.com в виде списка.\"\"\"\n",
    "    \n",
    "    title = title.strip()\n",
    "    url = f'https://www.epicurious.com/search/{title}?content=recipe'\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        url_ending = soup.find(class_=\"view-complete-item\", title=title)['href']\n",
    "        url_title = f'https://www.epicurious.com{url_ending}'\n",
    "        rating = soup.find(class_=\"view-complete-item\", title=title).parent.find(\"dd\")['data-rating']\n",
    "        return [title, url_title, rating]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "45fa43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Найдем ссылку для каждого рецепта\n",
    "title_list = []\n",
    "for elem in titles:\n",
    "    title_list.append(find_url_rating(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "64bff13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем список в датафрейм и сохраним его\n",
    "data_url = pd.DataFrame(title_list)\n",
    "data_url.to_csv('./data/links_to_recipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "568a41b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>rating_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17731</th>\n",
       "      <td>Chinese Barbecued Spareribs</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17732</th>\n",
       "      <td>Artichoke and Parmesan Risotto</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17733</th>\n",
       "      <td>Turkey Cream Puff Pie</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>Snapper on Angel Hair with Citrus Cream</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>Baked Ham with Marmalade-Horseradish Glaze</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                  Lentil, Apple, and Turkey Wrap   \n",
       "1      Boudin Blanc Terrine with Red Onion Confit   \n",
       "2                    Potato and Fennel Soup Hodge   \n",
       "3                 Mahi-Mahi in Tomato Olive Sauce   \n",
       "4                        Spinach Noodle Casserole   \n",
       "...                                           ...   \n",
       "17731                 Chinese Barbecued Spareribs   \n",
       "17732              Artichoke and Parmesan Risotto   \n",
       "17733                       Turkey Cream Puff Pie   \n",
       "17734     Snapper on Angel Hair with Citrus Cream   \n",
       "17735  Baked Ham with Marmalade-Horseradish Glaze   \n",
       "\n",
       "                                                     url  rating_url  \n",
       "0      https://www.epicurious.com/recipes/food/views/...         2.5  \n",
       "1      https://www.epicurious.com/recipes/food/views/...         4.6  \n",
       "2      https://www.epicurious.com/recipes/food/views/...         3.8  \n",
       "3      https://www.epicurious.com/recipes/food/views/...         4.8  \n",
       "4      https://www.epicurious.com/recipes/food/views/...         3.4  \n",
       "...                                                  ...         ...  \n",
       "17731  https://www.epicurious.com/recipes/food/views/...         4.0  \n",
       "17732  https://www.epicurious.com/recipes/food/views/...         4.1  \n",
       "17733  https://www.epicurious.com/recipes/food/views/...         4.5  \n",
       "17734  https://www.epicurious.com/recipes/food/views/...         4.3  \n",
       "17735  https://www.epicurious.com/recipes/food/views/...         4.5  \n",
       "\n",
       "[17736 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Прочитаем датафрейм и посмотрим есть ли пропущенные значения\n",
    "links_to_recipes = pd.read_csv('./data/links_to_recipes.csv', names=['title', 'url', 'rating_url'], header=0)\n",
    "links_to_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eb606cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Всего пропущено\n",
    "links_to_recipes['title'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "12c9584f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8                                   Korean Marinated Beef \n",
       "12       Banana-Chocolate Chip Cake With Peanut Butter ...\n",
       "21                                        \"Fried\" Chicken \n",
       "24                                Sea Salt-Roasted Pecans \n",
       "40                            Coconut-Key Lime Sheet Cake \n",
       "                               ...                        \n",
       "20018     Stuffed Onions with Spiced Lamb and Pomegranate \n",
       "20021    Dill-Crusted Pork Tenderloin With Farro, Pea, ...\n",
       "20026               Spinach with Chickpeas and Fried Eggs \n",
       "20029                         White Miso Peach/Pear/Apple \n",
       "20037                                             Russian \n",
       "Name: title, Length: 1661, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Найдем пропущенные значения\n",
    "missed_titles = titles.iloc[links_to_recipes.loc[links_to_recipes['title'].isna()].index]\n",
    "missed_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bdd1d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удалим пропуски\n",
    "links_to_recipes = links_to_recipes.loc[~links_to_recipes.title.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8013448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполним пропущенные значения похожими ссылками из гугла\n",
    "\n",
    "def find_in_google(query):\n",
    "    \n",
    "    \"\"\"Функция принимает на вход название рецепта и возвращает первую ссылку на рецепт в google.\"\"\"\n",
    "    \n",
    "    g_url = \"http://www.google.com/search?q=\" + query \n",
    "    res = requests.get(g_url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    try:\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.get('href').find('https') != -1:\n",
    "                l = link.get('href')\n",
    "                break\n",
    "        ind1=l.index('https')\n",
    "        ind2=l.index('&')\n",
    "        url = l[ind1:ind2]\n",
    "        return url\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2c8f5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_titles_list = []\n",
    "for elem in missed_titles:\n",
    "    missed_titles_list.append(find_in_google(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "42dfac8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://damndelicious.net/2019/04/21/korean-beef-bulgogi/',\n",
       " 'https://www.bonappetit.com/recipe/banana-chocolate-chip-cake-with-peanut-butter-frosting',\n",
       " 'https://volshebnaya-eda.ru/kollekcia-receptov/zharenaya-kurica-na-skovorode-s-korochkoj-i-chesnokom/',\n",
       " 'https://www.epicurious.com/recipes/food/views/sea-salt-roasted-pecans-233690',\n",
       " 'https://www.epicurious.com/recipes/food/views/coconut-key-lime-sheet-cake']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_titles_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c69bcc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>rating_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>Stuffed Onions with Spiced Lamb and Pomegranate</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>Dill-Crusted Pork Tenderloin With Farro, Pea, ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/70770/apple-...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>Spinach with Chickpeas and Fried Eggs</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>White Miso Peach/Pear/Apple</td>\n",
       "      <td>https://www.bbcgoodfood.com/recipes/thai-green...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>Russian</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1656   Stuffed Onions with Spiced Lamb and Pomegranate    \n",
       "1657  Dill-Crusted Pork Tenderloin With Farro, Pea, ...   \n",
       "1658             Spinach with Chickpeas and Fried Eggs    \n",
       "1659                       White Miso Peach/Pear/Apple    \n",
       "1660                                           Russian    \n",
       "\n",
       "                                                    url  rating_url  \n",
       "1656  https://www.epicurious.com/recipes/food/views/...        5.00  \n",
       "1657  https://www.allrecipes.com/recipe/70770/apple-...        5.00  \n",
       "1658  https://www.epicurious.com/recipes/food/views/...        5.00  \n",
       "1659  https://www.bbcgoodfood.com/recipes/thai-green...        3.75  \n",
       "1660  https://www.epicurious.com/recipes/food/views/...        0.00  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Преобразуем список в датафрейм\n",
    "df_missed = pd.DataFrame()\n",
    "df_missed['title'] = missed_titles.reset_index(drop=True)\n",
    "df_missed['url'] = missed\n",
    "df_missed['rating_url'] = title_rating.loc[missed_titles.index, 'rating'].reset_index(drop=True)\n",
    "df_missed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "342960b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>rating_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17731</th>\n",
       "      <td>Stuffed Onions with Spiced Lamb and Pomegranate</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17732</th>\n",
       "      <td>Dill-Crusted Pork Tenderloin With Farro, Pea, ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/70770/apple-...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17733</th>\n",
       "      <td>Spinach with Chickpeas and Fried Eggs</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>White Miso Peach/Pear/Apple</td>\n",
       "      <td>https://www.bbcgoodfood.com/recipes/thai-green...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>Russian</td>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                         Lentil, Apple, and Turkey Wrap   \n",
       "1             Boudin Blanc Terrine with Red Onion Confit   \n",
       "2                           Potato and Fennel Soup Hodge   \n",
       "3                        Mahi-Mahi in Tomato Olive Sauce   \n",
       "4                               Spinach Noodle Casserole   \n",
       "...                                                  ...   \n",
       "17731   Stuffed Onions with Spiced Lamb and Pomegranate    \n",
       "17732  Dill-Crusted Pork Tenderloin With Farro, Pea, ...   \n",
       "17733             Spinach with Chickpeas and Fried Eggs    \n",
       "17734                       White Miso Peach/Pear/Apple    \n",
       "17735                                           Russian    \n",
       "\n",
       "                                                     url  rating_url  \n",
       "0      https://www.epicurious.com/recipes/food/views/...        2.50  \n",
       "1      https://www.epicurious.com/recipes/food/views/...        4.60  \n",
       "2      https://www.epicurious.com/recipes/food/views/...        3.80  \n",
       "3      https://www.epicurious.com/recipes/food/views/...        4.80  \n",
       "4      https://www.epicurious.com/recipes/food/views/...        3.40  \n",
       "...                                                  ...         ...  \n",
       "17731  https://www.epicurious.com/recipes/food/views/...        5.00  \n",
       "17732  https://www.allrecipes.com/recipe/70770/apple-...        5.00  \n",
       "17733  https://www.epicurious.com/recipes/food/views/...        5.00  \n",
       "17734  https://www.bbcgoodfood.com/recipes/thai-green...        3.75  \n",
       "17735  https://www.epicurious.com/recipes/food/views/...        0.00  \n",
       "\n",
       "[17736 rows x 3 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Объединим оба датафрейма\n",
    "links_to_recipes_total = pd.concat([links_to_recipes, df_missed], axis=0).reset_index(drop=True)\n",
    "links_to_recipes_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c1e228dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавим к датафрейму столбцы с ингридиентами\n",
    "links_to_recipes_total = pd.concat([links_to_recipes_total, df], axis=1)\n",
    "links_to_recipes_total.drop('title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b443e7",
   "metadata": {},
   "source": [
    "Задание:\n",
    " - Сохраните новый датафрейм в CSV-файл, который вы будете использовать в своей основной программе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "917656d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>rating_url</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17731</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.750</td>\n",
       "      <td>998.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17732</th>\n",
       "      <td>https://www.allrecipes.com/recipe/70770/apple-...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.375</td>\n",
       "      <td>671.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17733</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.375</td>\n",
       "      <td>563.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>https://www.bbcgoodfood.com/recipes/thai-green...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.375</td>\n",
       "      <td>631.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>https://www.epicurious.com/recipes/food/views/...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.375</td>\n",
       "      <td>560.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17736 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  rating_url  rating  \\\n",
       "0      https://www.epicurious.com/recipes/food/views/...        2.50   2.500   \n",
       "1      https://www.epicurious.com/recipes/food/views/...        4.60   4.375   \n",
       "2      https://www.epicurious.com/recipes/food/views/...        3.80   3.750   \n",
       "3      https://www.epicurious.com/recipes/food/views/...        4.80   5.000   \n",
       "4      https://www.epicurious.com/recipes/food/views/...        3.40   3.125   \n",
       "...                                                  ...         ...     ...   \n",
       "17731  https://www.epicurious.com/recipes/food/views/...        5.00   3.750   \n",
       "17732  https://www.allrecipes.com/recipe/70770/apple-...        5.00   4.375   \n",
       "17733  https://www.epicurious.com/recipes/food/views/...        5.00   4.375   \n",
       "17734  https://www.bbcgoodfood.com/recipes/thai-green...        3.75   4.375   \n",
       "17735  https://www.epicurious.com/recipes/food/views/...        0.00   4.375   \n",
       "\n",
       "       calories  protein   fat  sodium  #cakeweek  #wasteless  \\\n",
       "0         426.0     30.0   7.0   559.0        0.0         0.0   \n",
       "1         403.0     18.0  23.0  1439.0        0.0         0.0   \n",
       "2         165.0      6.0   7.0   165.0        0.0         0.0   \n",
       "3           NaN      NaN   NaN     NaN        0.0         0.0   \n",
       "4         547.0     20.0  32.0   452.0        0.0         0.0   \n",
       "...         ...      ...   ...     ...        ...         ...   \n",
       "17731     998.0     55.0  80.0  2027.0        0.0         0.0   \n",
       "17732     671.0     22.0  28.0   583.0        0.0         0.0   \n",
       "17733     563.0     31.0  38.0   652.0        0.0         0.0   \n",
       "17734     631.0     45.0  24.0   517.0        0.0         0.0   \n",
       "17735     560.0     73.0  10.0  3698.0        0.0         0.0   \n",
       "\n",
       "       22-minute meals  ...  yellow squash  yogurt  yonkers  yuca  zucchini  \\\n",
       "0                  0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "1                  0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "2                  0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "3                  0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "4                  0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "...                ...  ...            ...     ...      ...   ...       ...   \n",
       "17731              0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "17732              0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "17733              0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "17734              0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "17735              0.0  ...            0.0     0.0      0.0   0.0       0.0   \n",
       "\n",
       "       cookbooks  leftovers  snack  snack week  turkey  \n",
       "0            0.0        0.0    0.0         0.0     1.0  \n",
       "1            0.0        0.0    0.0         0.0     0.0  \n",
       "2            0.0        0.0    0.0         0.0     0.0  \n",
       "3            0.0        0.0    0.0         0.0     0.0  \n",
       "4            0.0        0.0    0.0         0.0     0.0  \n",
       "...          ...        ...    ...         ...     ...  \n",
       "17731        0.0        0.0    0.0         0.0     0.0  \n",
       "17732        0.0        0.0    0.0         0.0     0.0  \n",
       "17733        0.0        0.0    0.0         0.0     1.0  \n",
       "17734        0.0        0.0    0.0         0.0     0.0  \n",
       "17735        0.0        0.0    0.0         0.0     0.0  \n",
       "\n",
       "[17736 rows x 681 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cохраним итоговый датафрейм\n",
    "links_to_recipes_total.to_csv('./data/url_result.csv', index=False)\n",
    "pd.read_csv('./data/url_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8152aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/list_of_possible_ingredients.pkl']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#В отдельный файл сохраним список всех ингридиентов\n",
    "list_of_possible_ingredients =  df_new.columns[:-1]\n",
    "joblib.dump(list_of_possible_ingredients, './data/list_of_possible_ingredients.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921b983",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a6474",
   "metadata": {},
   "source": [
    "Исходный датасет содержал 20052 рецептов и 680 признаков (ингридиенты). Из датасета удалены дубликаты и признаки, которые не относятся к ингридиентам.\n",
    "\n",
    "Машинное обучение - регерессия:\n",
    " - RMSE наивного регрессора: 1.32\n",
    " - Лучшие результаты показал ансамбль StackingRegressor, RMSE на test - 1.24, что немного лучше наивного регрессора.\n",
    "\n",
    "Машинное обучение - классификация:\n",
    " - После бинаризации целевой переменной в классы bad (0, 1) (невкусное), so-so (2, 3) (нормальное), great (4, 5) (вкусное):\n",
    "   \n",
    "   Accuracy наивного классификатора: 0.79\n",
    "\n",
    "   Лучшая модель SVC, accuracy на test - 0.80\n",
    " - Изменение метрики на precision_score, average=\"weighted\":\n",
    "\n",
    "   Лучшая модель - GradientBoostingClassifier с precision 0.74 - будет использоваться далее.\n",
    "\n",
    "\n",
    "Что можно улучшить:\n",
    " - улучшить прогноз за счет корректировки дисбаланса классов\n",
    " - оформление консольного приложения в виде telegram bot\n",
    " - дополнительный функционал (составление меню на день)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
