# lenta_hackathon

**ВЫВОДЫ ПО ПЕРВОЙ ЧАСТИ**

В данной части были изучены 4 файла с данными: `pr_df`, `st_df`, `sales_submission`, `sales_df_train`.

* **pr_df** - данные по товарной иерархии.

   Уникальных товаров - 2050. Товары делятся на 9 групп, далее делятся на 43 категории и 170 подкатегорий. 
   
   В столбце `pr_uom_id` (маркер, обозначающий продаётся товар на вес или в шт) данные разделились: 
   - 1279 товаров в группе 1;
   - 771 товар в группе 17.
   
   
* **st_df** - данные по магазинам.

   В данных 12 магазинов, они находятся в 7 городах. Дивизионов - 6. Форматов магазинов - 3 (1, 2, 4). Типов локации/окружения - 3 (1, 2, 3). Типов размера магазина - 6 (8, 12, 19, 20, 28, 32). 
   
   Активных магазинов - 10. По неактивным магазинам прогноз строить не нужно.
   
   
* **sales_submission** - данные для прогноза. 

   В файл входят столбцы с id магазина, id товара, датой и нулевым значением целевой переменной. Спрогнозировать спрос нужно на 14 дней за период с 19 июля по 01 августа 2023г. Всего магазинов в файле - 8. Именно по ним и будет строиться прогноз.


* **sales_df_train** - данные по продажам.

  В данных по продажам содержится информация о продажах 1973 товара в 12 магазинах. 
  Количество проданных товаров варьируется от 2 и 6 до 1074. Магазины с небольшим числом проданных товаров, возможно, закрыты или недавно открыты, так как для них указана информация только за 6 - 31 дней, всего таких магазинов - 3. Ассортимент товаров и их количество, скорее всего, зависит от размера магазина. 
  Период данных для большинства магазинов - 352 дня: от 01.08.2022 (10 магазинов из 12) до 18.07.2023, и один магазин - 309 дней: до 23.06.2023
  Период проведения промо-акций - в среднем от 299 до 468 в день у 6 магазинов, еще 3 магазина предположительно закрылись или недавно открылись, и по ним не корректо оценивать. У 3 магазинов количество проводимых акций колеблется от 8 до 131.
  
Далее были выялены и удалены строки с нулевым числом проданных товаров и ненулевыми продажами в рублях, а также с нулевыми продажами в рублях и ненулевым количеством проданных товаров. После этого были объединены данные по продажам с данными по товарной иерархии и по магазинам. 

Были созданы новые столбцы:  
- `total_sales_in_units` - общие продажи в штуках, включая промо;
- `total_sales_in_rub`- общие продажи в рублях, включая промо;
- `price_mean` - средняя цена товара;
- `promo_share` - доля продаж по промо.

Были удалены ненужные столбцы: `st_is_active`, `pr_sales_type_id`, `pr_sales_in_units`, `pr_promo_sales_in_units`, `pr_sales_in_rub`, `pr_promo_sales_in_rub`, `price`, `total_sales_in_rub_promo`. 

**ВЫВОДЫ ПО EDA**

В данном разделе был проведен разведочный анализ данных.

Было выявлено, что каждом столбце есть аномально большие и маленькие значения, а также отрицательные значения:
- Отрицательные значения оказались возвратами в столбцах количества товара и суммы продаж. Они были оставлены.
- В столбце `price_mean` оказались значения inf, так как продажи в штуках были равны 0, а сумма продаж не была равна 0. Такие строки были удалены.
- 48 товаров(17 категорий и 33 подкатегории) оказались с ценой ниже 5 рублей в 500 строках данных. Было решено сделать детекцию аномалий по цене.
- Было исследовано, что в столбце `pr_sales_in_units` имеет значение более 2000 штук товара 1 строка (1 магазин и 1 товар). Итоговые продажи по промо 15 апреля 2023г. составили 2348 штук. Общая сумма продаж 62 429 рублей, соответственно, цена за товар - 26.6 рублей. 16 апреля 2023г. была пасха, возможно, это тематические товары, например, куличи. Очевидно, что это сезонный товар, так как он продавался в период с 31 марта по 24 апреля. При проверке данного товара в других магазинах в указанные даты выяснилось, что часть магазинов имеет пик продаж в ту же дату, но у других магазинов размер пика и дата, на которую он приходится, - другие. Возможно, это зависит от размера магазина. Далее при проверке этого товара среди магазинов того же размера было устанговлено, что пиковое значение в два раза превышает среднее значение для своей группы магазинов.По остальным магазинам так же видны всплески продаж этого товара в период за неделю до пасхи. Делаем вывод: в данных есть товары, которые продаются постоянно (весь год) и сезонные.
- Было исследовано, что в столбце `pr_sales_in_rub` имеет значение более 180 000 рублей только 1 строка (1 магазин и 1 товар), однако этот товар продавался 259 дней. Были рассмотрены продажи этого товара в остальных магазинах, таких всплесков больше нигде не оказалось. Это были продажи по промо 21 марта 2023г. в количестве 440 штук. Общая сумма продаж - 183 265 рублей, соответственно, цена за товар - 416.5 рублей. Этот товар, в отличие от предыдущего, продается круглогодично. 

Очевидно, что в данных имеются выбросы различной природы, которые следует исследовать и исключить для получения качественных прогнозов модели.

Далее исследовались пропуски в данных. Например, при проверке по одному товару из одного магазина выяснилось, что при количестве наблюдений 346, продажи были только 132 дня. Поэтому пропуски были заполнены линейной интерполяцией (в 1-ом варианте) и 0 (во 2-м варианте). Пока еще не определились с окончательным вариантом.

После этого был изменен тип данных для столбцов `st_type_format_id`, `st_type_loc_id`, `st_type_size_id`, `pr_uom_id`, так как они категориальные.

Были созданы 3 функции:
- filling_blanks, которая возвращает восстановленный временной ряд, заполнив пропуски при помощи линейной интерполяции.
- concat_data для создания и объединения датафреймов с восстановленными временными рядами в один датафрейм.
- outliers_detection для детекции выбросов, которая сравнивает разницу между двумя соседними значениями продаж и заменяет значения, которые преышают 3 сигмы.
После применения функций стало видно по графику, что часть пиков, которые были похожи на выбросы уменьшились. 

Далее был проведен анализ временных рядов. Можно отметить сезонность, равную 1 неделе (7 дням). Для модели прогноза был сделан признак день недели с тригонометрическим преобразованием гиперпараметры max_lag, rolling_mean_size равными 7 дням (неделя). Было установлено при помощи критерия Дики-Фуллера, что временной ряд является стационарным.

Были проанализированы продаважи товаров по месяцам. Ожидаемо, что максимальные продажи были в декабре. Данные за июль 2023 неполные, поэтому видна сильная разница с июнем. Так как видны колебания продаж по месяцам - стоит добавить признак, соответствующий месяцу.

После этого исследовались сгруппированные данные.
Сгруппированные данные по группам товаров выявили топ-5 товаров:
1. `aab3238922bcc25a6f606eb525ffdc56`
2. `6512bd43d9caa6e02c990b0a82652dca`
3. `c74d97b01eae257e44aa9d5bade97baf`
4. `c51ce410c124a10e0db5e4b97fc2af39`
5. `c20ad4d76fe97759aa27a0c99bff6710`

Самая продаваемая группа товаров `aab3238922bcc25a6f606eb525ffdc56` включает в себя 9 категорий и 44 подкатегории, а также 695 товаров, что составляет 34% всех товаров, поэтому логично, что данная группа продается лучше остальных. Продажи около 160 млн. руб.
Вторая по продаваемости группа `6512bd43d9caa6e02c990b0a82652dca` отстает по выручке от первой на 18%, но при этом в ней в три раза меньше товаров. Продажи 130 млн. руб.
Корректное предсказание первых двух групп товаров дает нам 56% от общих продаж, первых трех групп - 75%, четырех - 89%, пяти - 97%.

Далее были сгруппированы топ-5 групп с категориями. Выяснилось, что топ-5 групп имеют все 43 категории, самых прибыльных из них - 20. Анализ продаж по категориям показывает, что для каждой группы основную долю продаж приносит только несколько категорий. Например, в первой по продажам группе 10 категорий, из них первые пять обеспечивают 96% продаж. Для второй группы из 9 категорий первые 4 категории дают 99% продаж.

Далее были сгруппированы топ-5 групп с топ-20 категориями. Было выявлено, что количество уникальных субкатегорий - 165, а количество самых прибыльных субкатегорий - 71, по которым продажи внутри каждой их групп максимальны.

**ВЫВОДЫ ПО МОДЕЛЯМ**

Было написано 2 класса: 
- `Optimizer`, в котором происходит предобработка данных перед обучением моделей и далее идет подбор гиперпараметров для модели;
- `Predictor`, в котором происходит предобработка данных перед обучением моделей и выполняется предсказание модели.

В работе были проверены следующие бустинги:
- XGBRegressor;
- LGBMRegressor;
- CatBoostRegressor. 

На малом количестве данных они давали  метрику **wape** в диапазоне 0.15 - 0.52.
На одном магазине получились следующие результаты.
| Model | Metric MAPE | Metric WAPE | params |
|-------|--------|--------|--------|
| XGBRegressor | 1541389327655981.5 | 0.8758104053008576 | {'learning_rate': 0.0571778195097089, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.689714689134693, 'colsample_bytree': 0.5679348507443351, 'lags': 49} |
| LGBMRegressor | 2824000227871695.0 | 0.8239011730729587 | {'learning_rate': 0.009364493010021614, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.3255884554207643, 'colsample_bytree': 0.6924169564850566, 'lags': 21} |
| CatBoostRegressor | 1626432290194898.0 | 0.6548929370237853 | {'learning_rate': 0.018186950525467666, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.722726167344909, 'colsample_bytree': 0.7229852367559773, 'lags': 28} |

**Поле для экспериментов**
- Провести анализ ошибок модели для улучшения точности прогноза.
- Заполнение пропусков (линейная интерполяция или нулевые продажи).
- Обработка выбросов. Стоит проверить, как изменится качество прогноза модели при удалении выбросов. Можно так же попробовать обрабатывать выбросы при помощи сторонник библиотек, например adtk.
- Нормализация данных.
- Нагенерировать признаки библиотекой TSFresh.
- Попробовать провести кластеризацию по магазинам, группам товаров и тд.
- При получении адекватного значения метрики сделать feature importance.
- Завернуть все в Docker.
