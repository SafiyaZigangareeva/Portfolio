# Матчинг товаров

## Описание проекта  и цель

- разработать алгоритм, который для всех товаров из validation.csv предложит несколько вариантов наиболее похожих товаров из base;
- оценить качество алгоритма по метрике accuracy@5.

## Описание данных 

- *base.csv* - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
- *target.csv -* обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из *base.csv*, который максимально похож на него (по мнению экспертов).
- *validation.csv* - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из *base.csv*
- *validation_answer.csv* - правильные ответы к предыдущему файлу.

## План работы

1. Открыть файлы и ознакомится с ними
2. 1 этап - faiss
 - Обучаем различные индексы и рассчитываем accuracy@k
 - Генерируем предсказания Faiss как кандидатов для второго этапа
3. 2 этап - Catboost
 - подбор гиперпараметров
4. Проверка на test моделей обоих этапов:
 - отдельно модели 1го уровня: faiss
 - отдельно двухуровненой модели: faiss + Catboost
 
## Выводы

Файл base содержит набор товаров 2 918 139 наблюдения и 72 столбца. Файл train 100 000 наблюдений и 73 столбца, target - наиболее соответствующий даному наблюдению товар из base. Файл validation так же содержит 100 000 строк. Пропусков и дубликатов нет.

После анализа данных из датасетов были удалены признаки, распределение которых было похоже на юниформ распределение или признаки с низкой вариативностью. Всего удалено 8 столбцов. Данные масштабированы для дальнейшего обучения.

Для использования в качестве модели первого этапа были обучены различные индексы Faiss с целью сравнения их метрик. результаты представлены в таблице:

| Index | Accuracy@20 | Index train time | Index search time |
|--------------|-----------|------------|------------|
| IndexFlatL2 | 75.531 | 2min 19s | 2min 57s |
| IndexFlatIP      | 75.632 | 1min 23s | 3min 47s |
| IndexHNSWFlat - 64/64/128 | 74.743 | 18min 11s | 40.8 s |
| IP+IndexIVFPQ | 75.636 | 4min 2s | 6min 3s |
| IndexLSH | 74.216 | 18.5 s | 3min 50s |

Для дальнейшего использования в качестве модели первого этапа будем использовать индекс **IndexFlatIP**, как лучшее соотношение точности и времени обучения.

**Результаты обучения моделей представлены в таблице:**

| Model | Метрика | train | Accuracy@5 test
|--------------|-----------|-----------|-----------|
| Faiss baseline | Accuracy@5 | 75.531 | 70.934 |
| Faiss 1 этап | Accuracy@20 | 76.136 | 76.094 |
| Faiss 1 этап + Catboost | Accuracy@5 | 70.575 | 70.934 |

Таким образом двухэтапная гибридная модель на данный момент показывает такие же результаты как простая модель faiss.


**Для обучения бустинга использовались признаки:**
- расстояние l2 между векторами
- покоординатная разность между векторами
В качестве метрики использовался Precision. Балансировка дисбаланса классов осуществлялась за счет взвешивания классов. 

**Самые важные признаки по мнению модели:**
1. Расстояние l2
2. Признаки 45, 5, 52, 8 - это поокординатные разности между соответствующими координатами векторов.

**Что можно улучшить:**
 - использовать снижение размерности для уменьшения времени на обучения и прогноз моделей.
 - feature engineering для увеличения точности прогноза faiss и catboost. Попробовать проанализировать ошибки модели или обратить внимание на признаки, которые модель catboost сочла самыми важными.
- объединить предсказания нескольких индексов
- обучить catboost с другой метрикой, например, ROC-AUC
